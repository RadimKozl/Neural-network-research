{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNt7VyE9dLsC1RrSvNVBNRV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RadimKozl/Neural-network-research/blob/main/LSTM_development.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **<font style=\"color:black\">Development of new version of LSTM function of PyTorch</font>**"
      ],
      "metadata": {
        "id": "AjZDYSwRlh_-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **<font style=\"color:purple\">Import libraries</font>**"
      ],
      "metadata": {
        "id": "AaJ4x5hXpkUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "seed = 3\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHT7j5eX5t69",
        "outputId": "d95fb536-8213-4b69-cb63-c669715d4b75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c8f087227b0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<font style=\"color:blue\">Introduction and theory</font>**\n",
        "\n",
        "<p>\n",
        "Long Short-Term Memory (LSTM) networks are a type of recurrent neural network (RNN) designed to address the vanishing gradient problem, which can make it difficult for standard RNNs to learn long-term dependencies. LSTMs have a more complex architecture than standard RNNs, with additional components that allow them to selectively remember or forget information over time.\n",
        "<p>\n",
        "\n",
        "![lstm-cell-2.png](data:image/png;base64,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)\n",
        "\n",
        "[resource of image](https://www.quantconnect.com/docs/v2/research-environment/applying-research/long-short-term-memory)"
      ],
      "metadata": {
        "id": "ZAoe_eopwjr0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **<font style=\"color:brown\">Key Components of LSTM</font>**\n",
        "\n",
        "1. ***Cell State (C_t):*** This is the horizontal line that runs straight through the entire chain, carrying information along the sequence.\n",
        "\n",
        "2. ***Hidden State (h_t):*** This is the output of the LSTM unit, which is also passed to the next LSTM unit in the sequence.\n",
        "\n",
        "3. ***Gates:*** LSTMs have three types of gates that control the flow of information:\n",
        "\n",
        "- ***Forget Gate (f_t):*** Decides what information to throw away from the cell state.\n",
        "- ***Input Gate (i_t):*** Decides what new information to store in the cell state.\n",
        "- ***Output Gate (o_t):*** Decides what the next hidden state should be.\n",
        "<br />\n",
        "\n",
        "### **<font style=\"color:brown\">Mathematical Formulation</font>**\n",
        "\n",
        "The LSTM updates can be described by the following equations:\n",
        "\n",
        "1. **Forget Gate:**\n",
        "\n",
        "$$f_t=\\sigma(Wf[h_{t1},x_t]+b_f)$$\n",
        "\n",
        "2. **Input Gate:**\n",
        "\n",
        "$$i_t=\\sigma(W_i[h_{t1},x_t]+b_i)$$\n",
        "\n",
        "3. **Candidate Cell State:**\n",
        "\n",
        "$$\\widetilde{C}_t=tanh(W_C[h_{t1},x_t]+b_C)$$\n",
        "\n",
        "4. **Update Cell State:**\n",
        "\n",
        "$$C_t=f_t \\odot C_{t1} + i_t \\odot \\widetilde{C}_t$$\n",
        "\n",
        "5. **Output Gate:**\n",
        "\n",
        "$$o_t=\\sigma(W_o[h_{t1},x_t]+b_o)$$\n",
        "\n",
        "6. **Hidden State:**\n",
        "\n",
        "$$h_t=o_t \\odot tanh(C_t)$$\n",
        "\n",
        "\n",
        "Here, $\\sigma$ is the sigmoid function, $tanh$ is the hyperbolic tangent function, $\\odot$ denotes element-wise multiplication, and $W_f,W_i,W_C,W_o$ are weight matrices."
      ],
      "metadata": {
        "id": "wKLRnny8b-OM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<font style=\"color:blue\">PyTorch Implementation</font>**\n",
        "\n",
        "In PyTorch, you can use the **nn.LSTM** module to create an *LSTM* layer. Here's a simple example of how to use it:"
      ],
      "metadata": {
        "id": "0IPnE1agtL6g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUwI7s1dkqrk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22aa61dd-4e90-499f-8ba2-50cc4cfc7143"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0228],\n",
            "        [ 0.0086],\n",
            "        [ 0.0073],\n",
            "        [ 0.0038],\n",
            "        [-0.0164]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Define an LSTM model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize hidden state with zeros\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        # Initialize cell state\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "\n",
        "        # Forward propagate LSTM\n",
        "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
        "\n",
        "        # Decode the hidden state of the last time step\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Example usage\n",
        "input_size = 10\n",
        "hidden_size = 20\n",
        "num_layers = 2\n",
        "output_size = 1\n",
        "\n",
        "model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
        "\n",
        "# Dummy input: (batch_size, seq_length, input_size)\n",
        "dummy_input = torch.randn(5, 3, input_size)\n",
        "output = model(dummy_input)\n",
        "print(output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<font style=\"color:blue\">Implementing an LSTM from scratch in *PyTorch*</font>**"
      ],
      "metadata": {
        "id": "ecq6tr7vd2bu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(LSTMCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Weights for input, forget, cell, and output gates\n",
        "        self.W_i = nn.Parameter(torch.Tensor(hidden_size, input_size + hidden_size))\n",
        "        self.b_i = nn.Parameter(torch.Tensor(hidden_size))\n",
        "\n",
        "        self.W_f = nn.Parameter(torch.Tensor(hidden_size, input_size + hidden_size))\n",
        "        self.b_f = nn.Parameter(torch.Tensor(hidden_size))\n",
        "\n",
        "        self.W_c = nn.Parameter(torch.Tensor(hidden_size, input_size + hidden_size))\n",
        "        self.b_c = nn.Parameter(torch.Tensor(hidden_size))\n",
        "\n",
        "        self.W_o = nn.Parameter(torch.Tensor(hidden_size, input_size + hidden_size))\n",
        "        self.b_o = nn.Parameter(torch.Tensor(hidden_size))\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        # Initialize weights and biases\n",
        "        for weight in [self.W_i, self.W_f, self.W_c, self.W_o]:\n",
        "            nn.init.xavier_uniform_(weight)\n",
        "        for bias in [self.b_i, self.b_f, self.b_c, self.b_o]:\n",
        "            nn.init.zeros_(bias)\n",
        "\n",
        "    def forward(self, x, h_prev, c_prev):\n",
        "        # Concatenate input and previous hidden state\n",
        "        combined = torch.cat((x, h_prev), dim=1)\n",
        "\n",
        "        # Compute gates\n",
        "        i_t = torch.sigmoid(torch.mm(combined, self.W_i.t()) + self.b_i)\n",
        "        f_t = torch.sigmoid(torch.mm(combined, self.W_f.t()) + self.b_f)\n",
        "        c_tilde = torch.tanh(torch.mm(combined, self.W_c.t()) + self.b_c)\n",
        "        o_t = torch.sigmoid(torch.mm(combined, self.W_o.t()) + self.b_o)\n",
        "\n",
        "        # Update cell state\n",
        "        c_t = f_t * c_prev + i_t * c_tilde\n",
        "\n",
        "        # Compute new hidden state\n",
        "        h_t = o_t * torch.tanh(c_t)\n",
        "\n",
        "        return h_t, c_t\n",
        "\n",
        "# Example usage\n",
        "input_size = 10\n",
        "hidden_size = 20\n",
        "\n",
        "lstm_cell = LSTMCell(input_size, hidden_size)\n",
        "\n",
        "# Dummy input: (batch_size, input_size)\n",
        "dummy_input = torch.randn(5, input_size)\n",
        "h_prev = torch.zeros(5, hidden_size)\n",
        "c_prev = torch.zeros(5, hidden_size)\n",
        "\n",
        "h_t, c_t = lstm_cell(dummy_input, h_prev, c_prev)\n",
        "print(\"Hidden State:\", h_t)\n",
        "print(\"Cell State:\", c_t)"
      ],
      "metadata": {
        "id": "fkNoxkJ8dgYK",
        "outputId": "f8b160e5-08b2-49c2-fff1-afcd49ad6731",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden State: tensor([[-0.0973,  0.0518,  0.1359,  0.1605, -0.0162, -0.2975,  0.1552,  0.0109,\n",
            "         -0.0031, -0.0307,  0.0769, -0.0477,  0.0121,  0.0961,  0.0746, -0.0845,\n",
            "          0.0091,  0.1223, -0.1350, -0.1493],\n",
            "        [-0.0231, -0.0657,  0.1393, -0.0051, -0.0636, -0.0885, -0.0025,  0.0142,\n",
            "         -0.0646,  0.0610,  0.1431, -0.2141,  0.0104,  0.1467, -0.1439,  0.0110,\n",
            "          0.1121, -0.0518, -0.0680, -0.1550],\n",
            "        [-0.1543,  0.1479, -0.0275,  0.0965,  0.1511, -0.0451,  0.1045, -0.2488,\n",
            "         -0.1114, -0.1376, -0.0292,  0.0849,  0.0206, -0.2270,  0.0945, -0.1194,\n",
            "         -0.1333,  0.0739, -0.0785,  0.1529],\n",
            "        [-0.0280,  0.1888,  0.1223,  0.2798,  0.0995,  0.0252, -0.1003,  0.0172,\n",
            "         -0.0353, -0.0634,  0.2490,  0.0250,  0.0518, -0.0346,  0.1327, -0.0633,\n",
            "          0.0481, -0.0264, -0.1125, -0.1477],\n",
            "        [ 0.0444,  0.0109,  0.1226,  0.2370,  0.0926, -0.1626, -0.1390,  0.2239,\n",
            "          0.1013, -0.1249,  0.2534,  0.0486,  0.1009,  0.0440,  0.2289,  0.0115,\n",
            "         -0.0524,  0.1112, -0.1200,  0.1641]], grad_fn=<MulBackward0>)\n",
            "Cell State: tensor([[-0.1463,  0.0779,  0.2078,  0.3401, -0.0373, -0.5283,  0.2774,  0.0161,\n",
            "         -0.0086, -0.0712,  0.1328, -0.0941,  0.0419,  0.1184,  0.0958, -0.1864,\n",
            "          0.0179,  0.3363, -0.2336, -0.2666],\n",
            "        [-0.0675, -0.1045,  0.5038, -0.0120, -0.1297, -0.3208, -0.0039,  0.0291,\n",
            "         -0.0907,  0.2430,  0.4518, -0.3156,  0.0273,  0.3018, -0.2994,  0.0228,\n",
            "          0.3083, -0.1666, -0.1344, -0.2235],\n",
            "        [-0.3336,  0.2798, -0.0565,  0.1900,  0.2636, -0.0986,  0.2050, -0.4479,\n",
            "         -0.2614, -0.3627, -0.0473,  0.1675,  0.0438, -0.3659,  0.1621, -0.2382,\n",
            "         -0.3083,  0.1428, -0.1476,  0.2434],\n",
            "        [-0.0956,  0.4256,  0.4256,  0.5600,  0.1924,  0.0866, -0.2268,  0.0352,\n",
            "         -0.0667, -0.2452,  0.4757,  0.0342,  0.1325, -0.0517,  0.2782, -0.1130,\n",
            "          0.1027, -0.0533, -0.2225, -0.2046],\n",
            "        [ 0.0934,  0.0201,  0.3497,  0.4353,  0.1986, -0.4752, -0.2428,  0.3031,\n",
            "          0.2280, -0.3061,  0.4273,  0.0785,  0.2332,  0.0560,  0.2955,  0.0223,\n",
            "         -0.1184,  0.1739, -0.3188,  0.2085]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<font style=\"color:blue\">Implementing an LSTM as function from scratch in *PyTorch*</font>**"
      ],
      "metadata": {
        "id": "8Uc3qANpfZRq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<font style=\"color:green\">Definition LSTM as function</font>**"
      ],
      "metadata": {
        "id": "Km5LCZK2s1BP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm_cell(input_tensor, hidden_state, cell_state, weights_ih, weights_hh, bias_ih, bias_hh):\n",
        "    gates = torch.matmul(input_tensor, weights_ih.t()) + bias_ih + torch.matmul(hidden_state, weights_hh.t()) + bias_hh\n",
        "    input_gate = torch.sigmoid(gates[:, 0:hidden_state.shape[1]])\n",
        "    forget_gate = torch.sigmoid(gates[:, hidden_state.shape[1]:2 * hidden_state.shape[1]])\n",
        "    output_gate = torch.sigmoid(gates[:, 2 * hidden_state.shape[1]:3 * hidden_state.shape[1]])\n",
        "    cell_gate = torch.tanh(gates[:, 3 * hidden_state.shape[1]:4 * hidden_state.shape[1]])\n",
        "    cell_state = forget_gate * cell_state + input_gate * cell_gate\n",
        "    hidden_state = output_gate * torch.tanh(cell_state)\n",
        "    return hidden_state, cell_state"
      ],
      "metadata": {
        "id": "FuLm9Av6fZyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **<font style=\"color:green\">Application lstm_cell function</font>**"
      ],
      "metadata": {
        "id": "Rs8nvJ2syixB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModelFunctional(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(LSTMModelFunctional, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.weights_ih = nn.Parameter(torch.Tensor(4 * hidden_size, input_size))\n",
        "        self.weights_hh = nn.Parameter(torch.Tensor(4 * hidden_size, hidden_size))\n",
        "        self.bias_ih = nn.Parameter(torch.Tensor(4 * hidden_size))\n",
        "        self.bias_hh = nn.Parameter(torch.Tensor(4 * hidden_size))\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        nn.init.xavier_uniform_(self.weights_ih)\n",
        "        nn.init.xavier_uniform_(self.weights_hh)\n",
        "        nn.init.zeros_(self.bias_ih)\n",
        "        nn.init.zeros_(self.bias_hh)\n",
        "\n",
        "    def forward(self, x, h_prev, c_prev):\n",
        "        batch_size, seq_length, _ = x.size()\n",
        "        hidden_seq = []\n",
        "\n",
        "        h_t, c_t = h_prev, c_prev\n",
        "        for t in range(seq_length):\n",
        "            h_t, c_t = lstm_cell(x[:, t, :], h_t, c_t, self.weights_ih, self.weights_hh, self.bias_ih, self.bias_hh)\n",
        "            hidden_seq.append(h_t)\n",
        "\n",
        "        # Use the hidden state of the last time step for the output\n",
        "        out = self.fc(hidden_seq[-1])\n",
        "        return out, h_t, c_t\n",
        "\n",
        "# Example usage\n",
        "input_size = 10\n",
        "hidden_size = 20\n",
        "\n",
        "lstm_cell = LSTMCell(input_size, hidden_size)\n",
        "\n",
        "# Dummy input: (batch_size, input_size)\n",
        "dummy_input = torch.randn(5, input_size)\n",
        "h_prev = torch.zeros(5, hidden_size)\n",
        "c_prev = torch.zeros(5, hidden_size)\n",
        "\n",
        "h_t, c_t = lstm_cell(dummy_input, h_prev, c_prev)\n",
        "print(\"Hidden State:\", h_t)\n",
        "print(\"Cell State:\", c_t)"
      ],
      "metadata": {
        "id": "mAA2KvyIyjXv",
        "outputId": "49922a95-2532-424c-f427-5744f1ef2f53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden State: tensor([[ 0.0858,  0.1628,  0.1159, -0.1233,  0.0329,  0.1039, -0.0645,  0.1323,\n",
            "          0.0777, -0.0246, -0.0279, -0.0986, -0.0848,  0.0360, -0.2882,  0.1021,\n",
            "          0.0916, -0.0509,  0.1745, -0.1289],\n",
            "        [ 0.2685, -0.0119, -0.1421, -0.0694,  0.0433,  0.1370,  0.0033, -0.3760,\n",
            "         -0.0515,  0.1041, -0.1045,  0.0100,  0.1204, -0.0468,  0.1778, -0.0225,\n",
            "         -0.2219, -0.1710,  0.0006, -0.0446],\n",
            "        [ 0.0522, -0.0498, -0.0652, -0.0503, -0.0022,  0.0910, -0.1353, -0.0701,\n",
            "          0.0654, -0.0510,  0.0517, -0.0802, -0.0332,  0.0346, -0.1258,  0.0390,\n",
            "         -0.0013,  0.0678, -0.0687, -0.1361],\n",
            "        [ 0.1389, -0.2207, -0.0078, -0.1218,  0.0273,  0.0943,  0.1491,  0.2600,\n",
            "          0.0694, -0.0435,  0.0701, -0.0528, -0.0307, -0.1070, -0.2187, -0.0548,\n",
            "          0.0007,  0.1083,  0.1124, -0.2144],\n",
            "        [-0.0434,  0.0200, -0.0083, -0.0382,  0.0857,  0.0419, -0.1693,  0.1107,\n",
            "          0.2008,  0.0618,  0.0051, -0.0753, -0.0479,  0.0421, -0.0668,  0.1252,\n",
            "          0.0586, -0.0774, -0.0339,  0.0821]], grad_fn=<MulBackward0>)\n",
            "Cell State: tensor([[ 0.1647,  0.2616,  0.1598, -0.3182,  0.0767,  0.1958, -0.1698,  0.1911,\n",
            "          0.1210, -0.0693, -0.0809, -0.1691, -0.3112,  0.0722, -0.5040,  0.1442,\n",
            "          0.2724, -0.0956,  0.2909, -0.2151],\n",
            "        [ 0.6783, -0.0204, -0.2762, -0.1297,  0.1522,  0.2640,  0.0158, -0.6494,\n",
            "         -0.1593,  0.1968, -0.2342,  0.0363,  0.2336, -0.1186,  0.3307, -0.0385,\n",
            "         -0.3326, -0.2422,  0.0020, -0.1085],\n",
            "        [ 0.1200, -0.1011, -0.1206, -0.1208, -0.0036,  0.2231, -0.2279, -0.1936,\n",
            "          0.1087, -0.0796,  0.0954, -0.1730, -0.0771,  0.0716, -0.2236,  0.0660,\n",
            "         -0.0018,  0.1160, -0.1240, -0.2557],\n",
            "        [ 0.4230, -0.4193, -0.0100, -0.3920,  0.0599,  0.1927,  0.5094,  0.3830,\n",
            "          0.1112, -0.2241,  0.1099, -0.0731, -0.1080, -0.1604, -0.6586, -0.0736,\n",
            "          0.0017,  0.2468,  0.1583, -0.3645],\n",
            "        [-0.0779,  0.0403, -0.0202, -0.1216,  0.1388,  0.1035, -0.3345,  0.2527,\n",
            "          0.3457,  0.1171,  0.0159, -0.1229, -0.1011,  0.1204, -0.1251,  0.2922,\n",
            "          0.1733, -0.1742, -0.0474,  0.1357]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<font style=\"color:blue\">Entropy theory</font>**\n",
        "\n",
        "------------------------------------------------\n",
        "\n",
        "- Entropy is a physical quantity that characterizes the degree of disorder (chaos) of a system at the microscopic level. The more microscopic arrangements (microstates) correspond to a given macroscopic state of the system, the higher its entropy.\n",
        "\n",
        "- Intuitively, we can think of entropy as a measure of our ignorance about the exact microscopic state of a system. If entropy is high, there are many possible microscopic arrangements that lead to the same observed macroscopic state, and we therefore know little about the internal organization of the system. Conversely, low entropy means that there are few possible microstates, and our description of the system is therefore more precise.\n",
        "\n",
        "#### ***Entropy appears in many areas of science:***\n",
        "\n",
        "- ***Thermodynamics***: Entropy is a key concept in the second law of thermodynamics, which states that the total entropy of an isolated system tends to increase with time or remain constant (for reversible processes). Spontaneous processes in isolated systems always lead to an increase in entropy.\n",
        "\n",
        "- ***Statistical mechanics***: Here, entropy is defined in terms of the number of microstates corresponding to a given macrostate.\n",
        "\n",
        "- ***Information theory***: Entropy here measures the amount of information contained in a message or data source. It expresses the average number of bits needed to encode a symbol from the source.\n",
        "\n",
        "#### ***Mathematical expression:***\n",
        "\n",
        "1. **Thermodynamic entropy (change):**\n",
        "\n",
        "- For a reversible process, the infinitesimal change in entropy $\\mathrm{d}S$ is defined as the ratio of the infinitesimal amount of heat $\\mathrm{d}Q$ supplied to the system to the absolute temperature $T$:\n",
        "\n",
        "$$ \\mathrm{d}S = \\mathrm{d}Q / T$$\n",
        "\n",
        "- For a general process between two states, the entropy change $ \\bigtriangleup S$ is given by the integral:\n",
        "\n",
        "$$ \\bigtriangleup S = \\int\\text{(from state 1 to state 2)} \\; \\mathrm{d}Q / T$$\n",
        "\n",
        "2. **Statistical entropy (Boltzmann definition):**\n",
        "\n",
        "- Ludwig Boltzmann defined the entropy $S$ microscopically in terms of the number of possible microstates $\\Omega$ corresponding to a given macroscopic state:\n",
        "\n",
        "$$S = k_B * ln(\\Omega)$$\n",
        "\n",
        "- where:\n",
        "  - $S$ is entropy\n",
        "  - $k_B$ is the Boltzmann constant (approximately $1.38 \\times 10^$ J/K)\n",
        "  - $ln(\\Omega)$ is the natural logarithm of the number of microstates\n",
        "\n",
        "- This equation shows that entropy is directly proportional to the logarithm of the number of possible arrangements of the particles of a system that lead to the observed macroscopic state. A higher number of microstates means a higher entropy.\n",
        "\n",
        "3. **Information entropy (Shannon entropy):**\n",
        "\n",
        "- In information theory, Claude Shannon defines the entropy $H$ of a discrete random variable $X$ with possible values $\\{ x_1,x_2, \\cdots, x_n \\}$ and corresponding probabilities $\\{ p_1,p_2, \\cdots, p_n \\}$ as:\n",
        "\n",
        "$$H(X) = - \\sum(i=1\\, \\text{until}\\, n) p_i * log_2(p_i)$$\n",
        "\n",
        "- where:\n",
        "  - $H(X)$ is the entropy of the random variable $X$ (measured in bits)\n",
        "  - $p_i$ is the probability of occurrence of value $x_i$\n",
        "  - $log_2(p_i)$ is the logarithm to base $2$ of the probability $p_i$\n",
        "\n",
        "- This equation measures the average amount of information (uncertainty) associated with a random variable. Maximum entropy occurs when all possible values are equally likely.\n",
        "\n",
        "#### ***Summary:***\n",
        "\n",
        "- Entropy is a fundamental concept that describes the tendency of systems to move towards greater disorder or uncertainty. Its mathematical expression varies depending on the context (thermodynamics, statistical mechanics, information theory), but all definitions share a common basis in the idea of the number of possible states or the probability of their occurrence."
      ],
      "metadata": {
        "id": "LtnLo6X86ece"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<font style=\"color:blue\">Increasing the efficiency of LSTM and implementing the attention mechanism</font>**\n",
        "\n",
        "<p>The fundamental idea behind implementing attention into an LSTM is to allow the LSTM at each time step to selectively focus on the most relevant parts of the entire input sequence (or the history of its own hidden states) when making a prediction or generating an output.</p>\n",
        "\n",
        "- **The Limitation of Standard LSTMs:**\n",
        "  - Standard LSTMs process sequential data step-by-step, maintaining a hidden state that aims to capture the essence of the sequence seen so far.\n",
        "  - While LSTMs are better at handling long-range dependencies than simple RNNs, they still have a bottleneck: the entire history of the sequence is compressed into a fixed-size hidden state vector at each time step.\n",
        "  - This fixed-size vector might struggle to retain all the crucial information from a long input sequence, especially when different parts of the sequence are important for different output steps.\n",
        "\n",
        "- **Solution using the attention mechanism:**\n",
        "  - Instead of relying solely on the last hidden state, attention mechanisms enable the LSTM to \"look back\" at the entire sequence of previous hidden states (or even the original input embeddings).\n",
        "  - It learns to assign a \"weight\" or \"importance score\" to each of these past hidden states (or inputs) based on their relevance to the current decoding step or prediction task.\n",
        "  - These weights determine how much influence each past state has on the current hidden state and the subsequent output.\n",
        "  - A \"context vector\" is then created by taking a weighted sum of these past hidden states (or inputs), where the weights are the attention scores. This context vector represents the focused information from the past that is most relevant right now.\n",
        "  - This context vector is then used in conjunction with the current LSTM hidden state to make a more informed decision.\n",
        "\n",
        "- **Summary:**\n",
        "  - Attention enhances LSTM's memory by providing a mechanism to dynamically access and weigh different parts of the input history, rather than relying solely on the compressed information in the last hidden state. This allows the model to handle longer sequences and focus on the most important information for the current task."
      ],
      "metadata": {
        "id": "qoqeX-c8Cmvr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **<font style=\"color:brown\">Mathematical Formulation for LSTM and implementing the attention mechanism</font>**\n",
        "\n",
        "**1. Inputs at time step $t$:**\n",
        "\n",
        "- $x_t$: Input tensor at time step $t$.\n",
        "- $h_{t1}$: Hidden state from the previous time step $t1$.\n",
        "- $c_{t1}$: The state of the cell from the previous time step $t1$.\n",
        "- $W_{ih}$: Weight matrix for transforming the input tensor.\n",
        "- $W_{hh}$: Weight matrix for the hidden state transformation.\n",
        "- $b_{ih}$: Bias vector for transforming the input tensor.\n",
        "- $W_{attn}$: Weight matrix for calculating attention scores.\n",
        "- $H_{\\text{prev}}=[h_1,h_2,...,h_{t1}]$: Sequence of hidden states from previous time steps.\n",
        "\n",
        "**2. Calculations at time step $t$:**\n",
        "\n",
        "- *Fused linear transformation for gates:*\n",
        "\n",
        "$$\n",
        "\\mathbf{gates} = x_t W_{ih}^T + b_{ih} + h_{t-1} W_{hh}^T + b_{hh}\n",
        "$$\n",
        "<br /><p>Here <strong>gates</strong> is the concatenation of vectors for the input gate, the forget gate, the output gate, and the candidate state of the cell.</p>\n",
        "\n",
        "- *Dividing gates and applying activation functions:*\n",
        "$$\n",
        "i_t = \\sigma(\\mathbf{\\text{gates}}_{[0:n]})\n",
        "$$\n",
        "\n",
        "$$\n",
        "f_t = \\sigma(\\mathbf{\\text{gates}}_{[n:2n]})\n",
        "$$\n",
        "\n",
        "$$\n",
        "o_t = \\sigma(\\mathbf{\\text{gates}}_{[2n:3n]})\n",
        "$$\n",
        "\n",
        "$$\n",
        "g_t = \\tanh(\\mathbf{\\text{gates}}_{[3n:4n]})\n",
        "$$\n",
        "\n",
        "where $n$ is the dimension of the hidden state and $\\sigma$ is the sigmoid function.\n",
        "\n",
        "- *Cell status update:*\n",
        "\n",
        "$$\n",
        "c_t = f_t \\odot c_{t-1} + i_t \\odot g_t\n",
        "$$\n",
        "\n",
        "where $\\odot$ denotes element by element multiplication.\n",
        "\n",
        "- *Calculating attention score:*\n",
        "\n",
        "$$\n",
        "\\mathbf{\\text{attention_scores}} = h_{t-1} W_{attn}^T\n",
        "$$\n",
        "\n",
        "- *Normalization of attention weights using Softmax:*\n",
        "\n",
        "$$\n",
        "\\mathbf{\\text{attention_weights_normalized}} = \\mathbf{\\text{softmax}}(\\mathbf{\\text{attention_scores}})\n",
        "$$\n",
        "\n",
        "The softmax function is applied over the dimension of the sequence of previous hidden states.\n",
        "\n",
        "- *Calculating the context vector:*\n",
        "\n",
        "$$\n",
        "\\mathbf{\\text{context_vector}} = \\mathbf{\\text{attention_weights_normalized}} \\, H_{prev}\n",
        "$$\n",
        "\n",
        "This is a weighted sum of the previous hidden states, where the weights are the normalized attention scores.\n",
        "\n",
        "- *Updating the hidden state with the context vector:*\n",
        "\n",
        "$$\n",
        "h_t = o_t \\odot \\tanh(c_t) + \\mathbf{\\text{context_vector}}\n",
        "$$\n",
        "\n",
        "**3. Outputs at time step $t$:**\n",
        "\n",
        "- $h_t$: New hidden state.\n",
        "- $c_t$: New cell state."
      ],
      "metadata": {
        "id": "gFpWNOr9e9pB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<font style=\"color:blue\">Implementing an LSTM with attention as function from scratch in *PyTorch*</font>**"
      ],
      "metadata": {
        "id": "rPbBx8DIVmdj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<font style=\"color:green\">Definition LSTM with attention as function</font>**"
      ],
      "metadata": {
        "id": "uDHC9E1uV5Rc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm_cell_with_attention(input_tensor, hidden_state, cell_state, weights_ih, weights_hh, bias_ih, bias_hh, attention_weights, previous_hidden_states, timestep):\n",
        "    \"\"\"\n",
        "    Calculation of a single step of an LSTM cell with an attention mechanism.\n",
        "\n",
        "    Args:\n",
        "        input_tensor: Input tensor (x_t)\n",
        "        hidden_state: Hidden state from the previous step (h_{t-1})\n",
        "        cell_state: Cell state from the previous step (c_{t-1})\n",
        "        weights_ih: Weights for the input tensor\n",
        "        weights_hh: Weights for the hidden state\n",
        "        bias_ih: Biases for the input tensor\n",
        "        bias_hh: Biases for the hidden state\n",
        "        attention_weights: Attention weights\n",
        "        previous_hidden_states: Hidden states from previous steps\n",
        "        timestep: Current timestep in the sequence\n",
        "\n",
        "    Returns:\n",
        "        New hidden state (h_t) and new cell state (c_t)\n",
        "    \"\"\"\n",
        "\n",
        "    # Linear transformation (fused)\n",
        "    gates = torch.matmul(input_tensor, weights_ih.t()) + bias_ih + torch.matmul(hidden_state, weights_hh.t()) + bias_hh\n",
        "\n",
        "    # Splitting into individual gates\n",
        "    input_gate = torch.sigmoid(gates[:, 0:hidden_state.shape[1]])\n",
        "    forget_gate = torch.sigmoid(gates[:, hidden_state.shape[1]:2 * hidden_state.shape[1]])\n",
        "    output_gate = torch.sigmoid(gates[:, 2 * hidden_state.shape[1]:3 * hidden_state.shape[1]])\n",
        "    cell_gate = torch.tanh(gates[:, 3 * hidden_state.shape[1]:4 * hidden_state.shape[1]])\n",
        "\n",
        "    # Updating the cell state\n",
        "    cell_state = forget_gate * cell_state + input_gate * cell_gate\n",
        "\n",
        "    # Attention mechanism\n",
        "    # Use previous hidden states up to the current timestep\n",
        "    relevant_hidden_states = previous_hidden_states[:, :timestep + 1, :]  # Shape: (batch_size, timestep + 1, hidden_size)\n",
        "    # Compute attention scores: (batch_size, timestep + 1)\n",
        "    attention_scores = torch.bmm(relevant_hidden_states, hidden_state.unsqueeze(2)).squeeze(2)\n",
        "    attention_weights_normalized = F.softmax(attention_scores, dim=1).unsqueeze(1)  # Shape: (batch_size, 1, timestep + 1)\n",
        "    context_vector = torch.bmm(attention_weights_normalized, relevant_hidden_states).squeeze(1)  # Shape: (batch_size, hidden_size)\n",
        "\n",
        "    # Updating the hidden state with the context vector\n",
        "    hidden_state = output_gate * torch.tanh(cell_state) + context_vector\n",
        "\n",
        "    return hidden_state, cell_state"
      ],
      "metadata": {
        "id": "VBSvnXAbl7PT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **<font style=\"color:green\">Application lstm_cell_with_attention function</font>**"
      ],
      "metadata": {
        "id": "7Qs4oJPUXlPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModelWithAttention(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(LSTMModelWithAttention, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.weights_ih = nn.Parameter(torch.Tensor(4 * hidden_size, input_size))\n",
        "        self.weights_hh = nn.Parameter(torch.Tensor(4 * hidden_size, hidden_size))\n",
        "        self.bias_ih = nn.Parameter(torch.Tensor(4 * hidden_size))\n",
        "        self.bias_hh = nn.Parameter(torch.Tensor(4 * hidden_size))\n",
        "        self.attention_weights = nn.Parameter(torch.Tensor(hidden_size, hidden_size))  # Not strictly needed now\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        nn.init.xavier_uniform_(self.weights_ih)\n",
        "        nn.init.xavier_uniform_(self.weights_hh)\n",
        "        nn.init.zeros_(self.bias_ih)\n",
        "        nn.init.zeros_(self.bias_hh)\n",
        "        nn.init.xavier_uniform_(self.attention_weights)\n",
        "\n",
        "    def forward(self, x, h_prev, c_prev):\n",
        "        batch_size, seq_length, _ = x.size()\n",
        "        hidden_seq = []\n",
        "        previous_hidden_states = torch.zeros(batch_size, seq_length, self.hidden_size, device=x.device)\n",
        "\n",
        "        h_t, c_t = h_prev, c_prev\n",
        "        for t in range(seq_length):\n",
        "            h_t, c_t = lstm_cell_with_attention(\n",
        "                x[:, t, :], h_t, c_t, self.weights_ih, self.weights_hh,\n",
        "                self.bias_ih, self.bias_hh, self.attention_weights, previous_hidden_states, t\n",
        "            )\n",
        "            hidden_seq.append(h_t)\n",
        "            previous_hidden_states[:, t, :] = h_t\n",
        "\n",
        "        out = self.fc(hidden_seq[-1])\n",
        "        return out, h_t, c_t\n",
        "\n",
        "\n",
        "# Example usage\n",
        "input_size = 10\n",
        "hidden_size = 20\n",
        "output_size = 1\n",
        "\n",
        "lstm_cell_attention = LSTMModelWithAttention(input_size, hidden_size, output_size)\n",
        "\n",
        "# Dummy input data: (batch_size, seq_length, input_size)\n",
        "batch_size = 5\n",
        "seq_length = 3\n",
        "\n",
        "# Create random input data\n",
        "dummy_input = torch.randn(batch_size, seq_length, input_size)\n",
        "\n",
        "# Initialize hidden and cell states\n",
        "h_prev = torch.zeros(batch_size, hidden_size)\n",
        "c_prev = torch.zeros(batch_size, hidden_size)\n",
        "\n",
        "# Forward pass\n",
        "outputs, h_t, c_t = lstm_cell_attention(dummy_input, h_prev, c_prev)\n",
        "\n",
        "# Print the outputs\n",
        "print(\"Outputs:\", outputs)\n",
        "print(\"Final Hidden State:\", h_t)\n",
        "print(\"Final Cell State:\", c_t)"
      ],
      "metadata": {
        "id": "1Yhbbgn1Yr-E",
        "outputId": "58cf3658-e641-4e0c-ef60-216d0a6cb6c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs: tensor([[ 0.1015],\n",
            "        [-0.0449],\n",
            "        [ 0.0010],\n",
            "        [ 0.0392],\n",
            "        [ 0.1341]], grad_fn=<AddmmBackward0>)\n",
            "Final Hidden State: tensor([[ 0.0882, -0.1784,  0.0039,  0.0837, -0.2128,  0.0820, -0.0321, -0.0066,\n",
            "          0.2133,  0.0309,  0.1246,  0.0259, -0.1533, -0.2955,  0.4019,  0.0460,\n",
            "          0.1894, -0.0618,  0.0306, -0.1781],\n",
            "        [ 0.1457, -0.0239,  0.2166, -0.2845, -0.2422, -0.1706,  0.2590,  0.0493,\n",
            "         -0.1159, -0.2796, -0.1448,  0.1293,  0.2497, -0.3194, -0.2288,  0.2632,\n",
            "          0.0342, -0.2411, -0.2518, -0.3998],\n",
            "        [ 0.0378,  0.0127,  0.1102,  0.0433, -0.0446, -0.0339, -0.3328,  0.2969,\n",
            "         -0.2958,  0.2327, -0.1518,  0.4233,  0.0942,  0.0331, -0.0283, -0.0565,\n",
            "         -0.1087, -0.0194,  0.1659, -0.0982],\n",
            "        [ 0.1655,  0.2254, -0.0366,  0.1867, -0.0936, -0.0770, -0.1562, -0.3606,\n",
            "         -0.1582,  0.0895,  0.0008,  0.0382,  0.0042, -0.0968,  0.1960, -0.2393,\n",
            "          0.0850, -0.1398, -0.0178,  0.1000],\n",
            "        [ 0.2024, -0.1608,  0.0993, -0.1798, -0.1143,  0.0867, -0.2902,  0.1732,\n",
            "          0.0101,  0.1888, -0.0825,  0.4052,  0.0683, -0.1843,  0.1704,  0.4148,\n",
            "         -0.2845,  0.1221,  0.1032, -0.0136]], grad_fn=<AddBackward0>)\n",
            "Final Cell State: tensor([[-0.0318, -0.1987, -0.0113,  0.1071, -0.2347,  0.1114, -0.1743,  0.0649,\n",
            "          0.1537,  0.2752,  0.1015,  0.1435, -0.3109, -0.4369,  0.3933, -0.0854,\n",
            "          0.3288, -0.1367,  0.1037, -0.1624],\n",
            "        [ 0.3002, -0.0890,  0.2720, -0.4933, -0.4107, -0.2499,  0.4748,  0.0262,\n",
            "         -0.2952, -0.2114, -0.3646,  0.3222,  0.4015, -0.5865, -0.4485,  0.3918,\n",
            "          0.0455, -0.4117, -0.3713, -0.4981],\n",
            "        [ 0.0464,  0.0296,  0.1711, -0.0249, -0.0579, -0.2338, -0.5259,  0.4935,\n",
            "         -0.6918,  0.3161, -0.2765,  0.4987,  0.1230, -0.0154, -0.0078, -0.0658,\n",
            "         -0.1185, -0.3173,  0.2459, -0.2346],\n",
            "        [ 0.1635,  0.3552, -0.0290,  0.2867, -0.0676, -0.1935, -0.3203, -0.1906,\n",
            "         -0.3163,  0.2466,  0.0699, -0.1388, -0.0654, -0.0012,  0.4155, -0.3182,\n",
            "         -0.0321, -0.1408,  0.1521,  0.0337],\n",
            "        [ 0.2767, -0.0794,  0.0521, -0.1047, -0.1478,  0.2749, -0.5450,  0.3211,\n",
            "         -0.0635,  0.3794, -0.0842,  0.5562,  0.1836, -0.2271,  0.2692,  0.4248,\n",
            "         -0.5032,  0.2135,  0.2980,  0.0161]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<font style=\"color:blue\">Implementing an LSTM with attention from scratch in *PyTorch*</font>**"
      ],
      "metadata": {
        "id": "VelDPFqTfE2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMCellWithAttention(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(LSTMCellWithAttention, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Weights for input-to-hidden transformations (gates)\n",
        "        self.W_i = nn.Parameter(torch.Tensor(hidden_size, input_size + hidden_size))  # Input gate\n",
        "        self.W_f = nn.Parameter(torch.Tensor(hidden_size, input_size + hidden_size))  # Forget gate\n",
        "        self.W_c = nn.Parameter(torch.Tensor(hidden_size, input_size + hidden_size))  # Cell gate\n",
        "        self.W_o = nn.Parameter(torch.Tensor(hidden_size, input_size + hidden_size))  # Output gate\n",
        "\n",
        "        # Biases for gates\n",
        "        self.b_i = nn.Parameter(torch.Tensor(hidden_size))\n",
        "        self.b_f = nn.Parameter(torch.Tensor(hidden_size))\n",
        "        self.b_c = nn.Parameter(torch.Tensor(hidden_size))\n",
        "        self.b_o = nn.Parameter(torch.Tensor(hidden_size))\n",
        "\n",
        "        # Attention layer (optional: could use a simpler dot-product attention if preferred)\n",
        "        self.attention = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "\n",
        "        # Final fully connected layer for output\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        # Initialize weights and biases using Xavier for weights and zeros for biases\n",
        "        for weight in [self.W_i, self.W_f, self.W_c, self.W_o]:\n",
        "            nn.init.xavier_uniform_(weight)\n",
        "        for bias in [self.b_i, self.b_f, self.b_c, self.b_o]:\n",
        "            nn.init.zeros_(bias)\n",
        "        nn.init.xavier_uniform_(self.attention.weight)\n",
        "\n",
        "    def forward(self, x, h_prev=None, c_prev=None):\n",
        "        \"\"\"\n",
        "        Forward pass for the LSTM cell with attention over the sequence.\n",
        "\n",
        "        Args:\n",
        "            x: Input tensor of shape (batch_size, seq_length, input_size)\n",
        "            h_prev: Previous hidden state (batch_size, hidden_size), optional\n",
        "            c_prev: Previous cell state (batch_size, hidden_size), optional\n",
        "\n",
        "        Returns:\n",
        "            output: Final output after fully connected layer (batch_size, output_size)\n",
        "            h_t: Final hidden state (batch_size, hidden_size)\n",
        "            c_t: Final cell state (batch_size, hidden_size)\n",
        "        \"\"\"\n",
        "        batch_size, seq_length, _ = x.size()\n",
        "\n",
        "        # Initialize hidden and cell states if not provided\n",
        "        if h_prev is None:\n",
        "            h_prev = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
        "        if c_prev is None:\n",
        "            c_prev = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
        "\n",
        "        # Store hidden states for attention\n",
        "        hidden_seq = []\n",
        "        previous_hidden_states = torch.zeros(batch_size, seq_length, self.hidden_size, device=x.device)\n",
        "\n",
        "        h_t, c_t = h_prev, c_prev\n",
        "        for t in range(seq_length):\n",
        "            # Concatenate current input and previous hidden state\n",
        "            combined = torch.cat((x[:, t, :], h_t), dim=1)\n",
        "\n",
        "            # Compute gates\n",
        "            i_t = torch.sigmoid(torch.mm(combined, self.W_i.t()) + self.b_i)\n",
        "            f_t = torch.sigmoid(torch.mm(combined, self.W_f.t()) + self.b_f)\n",
        "            c_tilde = torch.tanh(torch.mm(combined, self.W_c.t()) + self.b_c)\n",
        "            o_t = torch.sigmoid(torch.mm(combined, self.W_o.t()) + self.b_o)\n",
        "\n",
        "            # Update cell state\n",
        "            c_t = f_t * c_t + i_t * c_tilde\n",
        "\n",
        "            # Compute attention over previous hidden states up to this timestep\n",
        "            relevant_hidden_states = previous_hidden_states[:, :t + 1, :]  # Shape: (batch_size, t + 1, hidden_size)\n",
        "            if t > 0:  # Apply attention only if there are previous states\n",
        "                # Compute attention scores\n",
        "                attention_scores = torch.bmm(relevant_hidden_states, h_t.unsqueeze(2)).squeeze(2)  # Shape: (batch_size, t + 1)\n",
        "                attention_weights = F.softmax(attention_scores, dim=1).unsqueeze(1)  # Shape: (batch_size, 1, t + 1)\n",
        "                context_vector = torch.bmm(attention_weights, relevant_hidden_states).squeeze(1)  # Shape: (batch_size, hidden_size)\n",
        "            else:\n",
        "                context_vector = torch.zeros(batch_size, self.hidden_size, device=x.device)  # No context at t=0\n",
        "\n",
        "            # Update hidden state with attention\n",
        "            h_t = o_t * torch.tanh(c_t) + context_vector\n",
        "\n",
        "            # Store the hidden state\n",
        "            hidden_seq.append(h_t)\n",
        "            previous_hidden_states[:, t, :] = h_t\n",
        "\n",
        "        # Final output through fully connected layer\n",
        "        output = self.fc(h_t)\n",
        "\n",
        "        return output, h_t, c_t\n",
        "\n",
        "# Example usage\n",
        "input_size = 10\n",
        "hidden_size = 20\n",
        "output_size = 1\n",
        "\n",
        "# Initialize the model\n",
        "lstm_cell_attention = LSTMCellWithAttention(input_size, hidden_size, output_size)\n",
        "\n",
        "# Dummy input: (batch_size, seq_length, input_size)\n",
        "batch_size = 5\n",
        "seq_length = 3\n",
        "dummy_input = torch.randn(batch_size, seq_length, input_size)\n",
        "\n",
        "# Optional: Initialize hidden and cell states (if not provided, they'll be zero-initialized)\n",
        "h_prev = torch.zeros(batch_size, hidden_size)\n",
        "c_prev = torch.zeros(batch_size, hidden_size)\n",
        "\n",
        "# Forward pass\n",
        "output, h_t, c_t = lstm_cell_attention(dummy_input, h_prev, c_prev)\n",
        "\n",
        "# Print the outputs\n",
        "print(\"Output:\", output)\n",
        "print(\"Final Hidden State:\", h_t)\n",
        "print(\"Final Cell State:\", c_t)"
      ],
      "metadata": {
        "id": "18f_qGdwfFYX",
        "outputId": "b3c73774-9576-4de7-cc51-916f2ac9e707",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: tensor([[-0.0171],\n",
            "        [ 0.0226],\n",
            "        [-0.0569],\n",
            "        [ 0.0600],\n",
            "        [-0.1260]], grad_fn=<AddmmBackward0>)\n",
            "Final Hidden State: tensor([[-5.0803e-02,  1.1980e-01,  8.7436e-02, -3.3476e-01,  3.9581e-01,\n",
            "          1.7821e-02,  2.9325e-01, -2.4422e-01,  2.0424e-01, -9.5694e-02,\n",
            "         -1.7557e-01,  9.6278e-02,  1.1567e-02, -2.7676e-02,  9.1627e-02,\n",
            "         -6.6106e-01,  3.7325e-02,  3.6945e-02,  4.7969e-02,  2.7416e-01],\n",
            "        [-1.2381e-01, -1.7818e-01,  1.8445e-01, -1.8795e-01,  1.8647e-01,\n",
            "          8.4210e-02,  2.1043e-01,  1.1031e-01, -2.8562e-02,  2.0418e-01,\n",
            "          2.8955e-01,  3.5968e-01,  2.4528e-02, -2.6598e-01, -3.2298e-01,\n",
            "         -1.2211e-01, -1.8676e-01,  6.5903e-02, -1.2091e-01, -8.8776e-02],\n",
            "        [-9.0912e-02, -1.3150e-01,  4.1204e-01, -2.2673e-01,  1.2524e-01,\n",
            "          8.1597e-02,  2.7153e-01,  9.1321e-02,  3.7137e-01, -1.0550e-01,\n",
            "          5.0954e-02, -1.3432e-01, -2.6648e-01,  7.4932e-02,  2.0463e-01,\n",
            "         -9.9504e-02,  1.9934e-01, -2.2518e-05, -2.2970e-01,  2.1898e-01],\n",
            "        [ 1.0486e-02,  4.0442e-02,  7.6521e-02,  1.7711e-01,  2.7920e-01,\n",
            "         -3.0223e-01,  2.5930e-01,  3.0424e-01, -1.9966e-01, -8.5417e-02,\n",
            "         -5.1518e-02, -7.1642e-02,  2.6215e-01, -3.9460e-01, -1.0602e-01,\n",
            "          8.4293e-02,  6.1665e-02,  1.7370e-01,  1.0755e-01, -3.9097e-01],\n",
            "        [ 3.3812e-01,  2.5971e-01, -1.7952e-01, -2.4364e-01,  2.5121e-02,\n",
            "          1.1067e-01, -9.5231e-02, -3.9475e-02, -2.4716e-01,  3.9107e-02,\n",
            "          2.3224e-01, -2.9472e-01, -6.4763e-02,  4.1718e-02, -3.5200e-02,\n",
            "         -1.8291e-01, -6.7833e-02, -3.0380e-01, -1.8509e-02, -9.5704e-02]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Final Cell State: tensor([[-0.0924,  0.2015, -0.0213, -0.4845,  0.4386,  0.1104,  0.3204, -0.0015,\n",
            "          0.2207, -0.0911, -0.2502,  0.2321, -0.2052,  0.0763,  0.0441, -0.6090,\n",
            "          0.0702, -0.0157, -0.0673,  0.3399],\n",
            "        [-0.1098,  0.0913,  0.2001, -0.5413,  0.2837,  0.1848,  0.4224,  0.0075,\n",
            "          0.0282,  0.7116,  0.4246,  0.6842, -0.0891, -0.1064, -0.5060, -0.2442,\n",
            "         -0.0386,  0.0670, -0.2704, -0.0403],\n",
            "        [-0.1352, -0.2797,  0.5951, -0.1274, -0.0130, -0.1145,  0.2443,  0.0136,\n",
            "          0.4103, -0.2623, -0.0641, -0.3720, -0.2774, -0.0196,  0.2154, -0.0503,\n",
            "          0.4335,  0.0934, -0.1527,  0.3725],\n",
            "        [ 0.1792, -0.2396,  0.0876,  0.3864,  0.1870, -0.2153,  0.1039,  0.5297,\n",
            "         -0.5174, -0.1081,  0.2125, -0.1437,  0.3163, -0.4129, -0.1579,  0.3070,\n",
            "         -0.1843,  0.1893,  0.1197, -0.5666],\n",
            "        [ 0.5161,  0.3902, -0.2373, -0.2697,  0.1659,  0.2759, -0.2481,  0.0862,\n",
            "         -0.4869, -0.0698,  0.3111, -0.5098, -0.2262,  0.0383, -0.0798, -0.1599,\n",
            "          0.0281, -0.4327, -0.1665, -0.0415]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<font style=\"color:blue\">Implementation of entropy into the attention mechanism in LSTM networks</font>**\n",
        "\n",
        "#### ***Overview of methods:***\n",
        "\n",
        "**1. Entropic regularization:**\n",
        "\n",
        "- **Basic idea:** This variant tries to influence the distribution of attention weights so that it is not too \"sharp\" or focused on only a few elements from the past. It is inspired by the principle of entropy, which prefers a more even distribution of probabilities (in this case, weights).\n",
        "\n",
        "- **How it works:** During training, the entropy of the normalized attention weights is calculated. If the weights are too concentrated (low entropy), a penalty is added to the model's loss function. This forces the model to assign attention to a wider range of past states, potentially preventing over-reliance on a few \"most important\" points and improving generalization.\n",
        "\n",
        "- **Physical analogy:** Imagine a system of particles that can move in space. Low entropy would correspond to a state where all the particles are clustered in a small area. High entropy would correspond to a uniform distribution of particles throughout the space. Low entropy regularization penalizes attention clustering.\n",
        "\n",
        "**2. Time factor (time decay):**\n",
        "\n",
        "- **Basic idea:** This variant introduces a mechanism that reduces the importance (weight) of older information from the past when calculating the context vector. This simulates the effect of entropy, where information becomes less relevant or \"degrades\" over time.\n",
        "\n",
        "- **How it works:** A time-dependent function (such as exponential decay) is applied to the attention weights. The further back in time a hidden state is, the less weight it has in computing the context vector. This forces the model to focus more on recent history, which can be useful in tasks where recent events are more relevant for prediction.\n",
        "\n",
        "- **Physical analogy:** Think of memories. The older a memory is, the less detailed and less reliable it becomes (unless it is actively retrieved). The time factor in attention simulates this \"forgetting\" of older information.\n",
        "\n",
        "**3. Entropic regularization + Time factor + randomness:**\n",
        "\n",
        "- **Basic idea:** This variant combines the advantages of entropic regularization and the time factor, and additionally introduces an element of randomness into the process of choosing what the model will focus on. It is intended to simulate the chaotic movement of particles and the exploration of the space of possible solutions.\n",
        "\n",
        "- **How it works:** At each step, there is a certain probability that either entropic regularization, a time factor, or some attention weights are randomly reset (simulating the \"heat flow\" of attention). This should help the model escape local minima during training and explore a wider space of possible attention distributions.\n",
        "\n",
        "- **Physical analogy:** Imagine a system with many interacting particles at a certain temperature. The particles are constantly randomly oscillating and interacting. This variant tries to simulate this dynamics in the attention mechanism to avoid getting stuck in suboptimal states.\n",
        "\n",
        "#### ***Summary:***\n",
        "\n",
        "Overall, these variants explore different ways in which the principles of entropy and its associated phenomena (tendency to disorder, information degradation over time, random fluctuations) can influence the attention mechanism in LSTM networks and potentially improve their ability to process long sequences and generalize."
      ],
      "metadata": {
        "id": "5_pK9UZDqBPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<font style=\"color:aqua\">Entropic regularization</font>**"
      ],
      "metadata": {
        "id": "nbhebbG9sCxy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **<font style=\"color:brown\">Mathematical expression with entropic regularization:</font>**\n",
        "\n",
        "1. **Equations:**\n",
        "\n",
        "- *Fused linear transformation for gates: (Same as before)*\n",
        "\n",
        "$$\\text{gates} = x_t W_{ih}^T + b_{ih} + h_{t-1} W_{hh}^T + b_{hh}$$\n",
        "\n",
        "- *Dividing the gates and applying activation functions: (Same as before)*\n",
        "\n",
        "$$i_t = \\sigma(\\text{gates}_{[0:n]})$$\n",
        "$$f_t = \\sigma(\\text{gates}_{[n:2n]})$$\n",
        "$$o_t = \\sigma(\\text{gates}_{[2n:3n]})$$\n",
        "$$g_t = \\tanh(\\text{gates}_{[3n:4n]})$$\n",
        "\n",
        "- *Cell status update: (Same as before)*\n",
        "\n",
        "$$c_t = f_t \\odot c_{t-1} + i_t \\odot g_t$$\n",
        "\n",
        "- *Attention score calculation: (Same as before)*\n",
        "\n",
        "$$\\text{attention_scores} = h_{t-1} W_{attn}^T$$\n",
        "\n",
        "- *Normalizing attention weights using Softmax: (Same as before)*\n",
        "\n",
        "$$\\text{attention_weights_normalized} = \\text{softmax}(\\text{attention_scores})$$\n",
        "\n",
        "- *Context vector calculation: (Same as before)*\n",
        "\n",
        "$$\\text{context_vector} = \\text{attention_weights_normalized} \\, H_{prev}$$\n",
        "\n",
        "- *Calculating the entropy of attention weights:*\n",
        "\n",
        "$$\n",
        "H(\\mathbf{a}) = - \\frac{1}{B} \\sum_{b=1}^{B} \\sum_{i=1}^{T-1} a_{b,i} \\log(a_{b,i} + \\epsilon)\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "  1. $a=\\text{attention_weights_normalized}$ is a matrix of normalized attention weights ($\\text{dimension Batch Size B} \\times {Length}$ of previous sequence $T1$).\n",
        "\n",
        "  2. $a_{b,i}$ is the `i-th` attention weight for the `b-th` element in the batch.\n",
        "  3. $\\epsilon$ is a small positive number (e.g. 1e8) for the numerical stability of the logarithm.\n",
        "  4. The result is the average entropy over all elements in the batch.\n",
        "  <br />\n",
        "\n",
        "- *Updating the hidden state with context vector and entropic regularization:*\n",
        "\n",
        "$$\n",
        "h_t = o_t \\odot \\tanh(c_t) + \\text{context_vector} - \\lambda_{entropy} \\cdot H(\\mathbf{a}) \\cdot \\mathbf{1}\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "  1. $\\lambda_{entropy}$ is the entropic regularization coefficient (hyperparameter). Determines how strongly the penalty will be for models that produce too \"spiky\" attention distributions (low entropy).\n",
        "  2. $H(\\mathbf{a})$ is the calculated entropy.\n",
        "  3. $\\mathbf{1}$ is a vector of ones of the same dimension as the hidden state ht. In this way, the entropy penalty is applied to all dimensions of the hidden state."
      ],
      "metadata": {
        "id": "Y0GW5BFhW6Iy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **<font style=\"color:darkgreen\">Implementing an LSTM with Entropic regularization as function from scratch in *PyTorch*</font>**"
      ],
      "metadata": {
        "id": "K7m-NR7oqdSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **<font style=\"color:green\">Definition LSTM with Entropic regularization as function</font>**"
      ],
      "metadata": {
        "id": "wpfu0m_ar7UB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm_cell_attention_entropy_reg(input_tensor, hidden_state, cell_state, weights_ih, weights_hh, bias_ih, bias_hh, attention_weights, previous_hidden_states, lambda_entropy, timestep):\n",
        "    \"\"\"\n",
        "    Calculation of a single step of an LSTM cell with an attention mechanism and entropic regularization.\n",
        "\n",
        "    Args:\n",
        "        input_tensor: Input tensor (x_t)\n",
        "        hidden_state: Hidden state from the previous step (h_{t-1})\n",
        "        cell_state: Cell state from the previous step (c_{t-1})\n",
        "        weights_ih: Weights for the input tensor\n",
        "        weights_hh: Weights for the hidden state\n",
        "        bias_ih: Biases for the input tensor\n",
        "        bias_hh: Biases for the hidden state\n",
        "        attention_weights: Attention weights (not used directly here, kept for compatibility)\n",
        "        previous_hidden_states: Hidden states from previous steps\n",
        "        lambda_entropy: Coefficient of entropic regularization\n",
        "        timestep: Current timestep in the sequence\n",
        "\n",
        "    Returns:\n",
        "        New hidden state (h_t) and new cell state (c_t)\n",
        "    \"\"\"\n",
        "    # Linear transformation (fused)\n",
        "    gates = torch.matmul(input_tensor, weights_ih.t()) + bias_ih + torch.matmul(hidden_state, weights_hh.t()) + bias_hh\n",
        "\n",
        "    # Splitting into individual gates\n",
        "    input_gate = torch.sigmoid(gates[:, 0:hidden_state.shape[1]])\n",
        "    forget_gate = torch.sigmoid(gates[:, hidden_state.shape[1]:2 * hidden_state.shape[1]])\n",
        "    output_gate = torch.sigmoid(gates[:, 2 * hidden_state.shape[1]:3 * hidden_state.shape[1]])\n",
        "    cell_gate = torch.tanh(gates[:, 3 * hidden_state.shape[1]:4 * hidden_state.shape[1]])\n",
        "\n",
        "    # Updating the cell state\n",
        "    cell_state = forget_gate * cell_state + input_gate * cell_gate\n",
        "\n",
        "    # Attention mechanism\n",
        "    relevant_hidden_states = previous_hidden_states[:, :timestep + 1, :]  # Shape: (batch_size, timestep + 1, hidden_size)\n",
        "    if timestep > 0:  # Only apply attention if there are previous states\n",
        "        # Compute attention scores over the sequence\n",
        "        attention_scores = torch.bmm(relevant_hidden_states, hidden_state.unsqueeze(2)).squeeze(2)  # Shape: (batch_size, timestep + 1)\n",
        "        attention_weights_normalized = F.softmax(attention_scores, dim=1)  # Shape: (batch_size, timestep + 1)\n",
        "        context_vector = torch.bmm(attention_weights_normalized.unsqueeze(1), relevant_hidden_states).squeeze(1)  # Shape: (batch_size, hidden_size)\n",
        "\n",
        "        # Calculate entropy of attention weights\n",
        "        entropy = -torch.sum(attention_weights_normalized * torch.log(attention_weights_normalized + 1e-8), dim=1).mean()\n",
        "    else:\n",
        "        context_vector = torch.zeros_like(hidden_state, device=hidden_state.device)  # No attention at t=0\n",
        "        entropy = torch.tensor(0.0, device=hidden_state.device)\n",
        "\n",
        "    # Update hidden state with context vector and entropy regularization\n",
        "    hidden_state = output_gate * torch.tanh(cell_state) + context_vector - lambda_entropy * entropy\n",
        "\n",
        "    return hidden_state, cell_state"
      ],
      "metadata": {
        "id": "N4kTnfnWrjCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **<font style=\"color:green\">Application lstm_cell_attention_entropy_reg function</font>**"
      ],
      "metadata": {
        "id": "Xzs51B_3sl1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModelWithAttentionEntropyReg(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, lambda_entropy):\n",
        "        super(LSTMModelWithAttentionEntropyReg, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lambda_entropy = lambda_entropy\n",
        "        self.weights_ih = nn.Parameter(torch.Tensor(4 * hidden_size, input_size))\n",
        "        self.weights_hh = nn.Parameter(torch.Tensor(4 * hidden_size, hidden_size))\n",
        "        self.bias_ih = nn.Parameter(torch.Tensor(4 * hidden_size))\n",
        "        self.bias_hh = nn.Parameter(torch.Tensor(4 * hidden_size))\n",
        "        self.attention_weights = nn.Parameter(torch.Tensor(hidden_size, hidden_size))  # Kept for compatibility, not used directly\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        nn.init.xavier_uniform_(self.weights_ih)\n",
        "        nn.init.xavier_uniform_(self.weights_hh)\n",
        "        nn.init.zeros_(self.bias_ih)\n",
        "        nn.init.zeros_(self.bias_hh)\n",
        "        nn.init.xavier_uniform_(self.attention_weights)\n",
        "\n",
        "    def forward(self, x, h_prev, c_prev):\n",
        "        batch_size, seq_length, _ = x.size()\n",
        "        hidden_seq = []\n",
        "        previous_hidden_states = torch.zeros(batch_size, seq_length, self.hidden_size, device=x.device)\n",
        "\n",
        "        h_t, c_t = h_prev, c_prev\n",
        "        for t in range(seq_length):\n",
        "            h_t, c_t = lstm_cell_attention_entropy_reg(\n",
        "                x[:, t, :], h_t, c_t, self.weights_ih, self.weights_hh,\n",
        "                self.bias_ih, self.bias_hh, self.attention_weights, previous_hidden_states, self.lambda_entropy, t\n",
        "            )\n",
        "            hidden_seq.append(h_t)\n",
        "            previous_hidden_states[:, t, :] = h_t\n",
        "\n",
        "        out = self.fc(hidden_seq[-1])\n",
        "        return out, h_t, c_t\n",
        "\n",
        "# Example usage\n",
        "input_size = 10\n",
        "hidden_size = 20\n",
        "output_size = 1\n",
        "lambda_entropy = 0.1  # Example value for entropic regularization coefficient\n",
        "\n",
        "lstm_cell_attention_entropy = LSTMModelWithAttentionEntropyReg(input_size, hidden_size, output_size, lambda_entropy)\n",
        "\n",
        "# Dummy input data: (batch_size, seq_length, input_size)\n",
        "batch_size = 5\n",
        "seq_length = 3\n",
        "\n",
        "# Create random input data\n",
        "dummy_input = torch.randn(batch_size, seq_length, input_size)\n",
        "\n",
        "# Initialize hidden and cell states\n",
        "h_prev = torch.zeros(batch_size, hidden_size)\n",
        "c_prev = torch.zeros(batch_size, hidden_size)\n",
        "\n",
        "# Forward pass\n",
        "outputs, h_t, c_t = lstm_cell_attention_entropy(dummy_input, h_prev, c_prev)\n",
        "\n",
        "# Print the outputs\n",
        "print(\"Outputs:\", outputs)\n",
        "print(\"Final Hidden State:\", h_t)\n",
        "print(\"Final Cell State:\", c_t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_C6gHON5smJa",
        "outputId": "63087c8f-1f0f-41f7-c865-525ba3890efc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs: tensor([[-0.2039],\n",
            "        [-0.1822],\n",
            "        [-0.1833],\n",
            "        [-0.2257],\n",
            "        [-0.2803]], grad_fn=<AddmmBackward0>)\n",
            "Final Hidden State: tensor([[-0.1896, -0.1644, -0.0325, -0.0789, -0.0756,  0.0474, -0.0922,  0.0016,\n",
            "         -0.2455, -0.0911, -0.2400,  0.0412, -0.2640,  0.0282, -0.1880, -0.0941,\n",
            "         -0.2342, -0.1917, -0.2191, -0.0964],\n",
            "        [-0.2550,  0.1991, -0.2754, -0.0173,  0.0715, -0.4109, -0.1724, -0.4193,\n",
            "         -0.2217, -0.2233,  0.0362, -0.1654, -0.1825, -0.3053, -0.0974, -0.3747,\n",
            "         -0.0735,  0.0789, -0.3060,  0.1721],\n",
            "        [-0.2237, -0.2980, -0.1827, -0.1323, -0.0474, -0.0176, -0.0117, -0.2980,\n",
            "         -0.2792, -0.6225, -0.1663,  0.2069,  0.0129, -0.0955, -0.2543, -0.5427,\n",
            "         -0.2583,  0.0565, -0.4102, -0.0188],\n",
            "        [-0.3586, -0.0448, -0.2611,  0.0575,  0.1943, -0.1495, -0.1387, -0.2904,\n",
            "         -0.3516,  0.0155,  0.1046,  0.0401, -0.2491, -0.2471,  0.0311, -0.1972,\n",
            "         -0.1641, -0.0288,  0.0086, -0.0520],\n",
            "        [-0.0359, -0.3471, -0.1172, -0.0345, -0.0137,  0.1026, -0.2706, -0.1190,\n",
            "         -0.1441, -0.3913, -0.0458, -0.1036, -0.2059,  0.1990, -0.3233,  0.0352,\n",
            "         -0.3417,  0.1696, -0.2193,  0.0327]], grad_fn=<SubBackward0>)\n",
            "Final Cell State: tensor([[-0.0391,  0.1549,  0.0454,  0.0853,  0.0071,  0.1861, -0.0472,  0.1125,\n",
            "         -0.0070, -0.0115, -0.2050,  0.1663, -0.2891,  0.3936, -0.2350,  0.2969,\n",
            "         -0.0620,  0.0295, -0.1422,  0.1115],\n",
            "        [-0.1223,  0.4986, -0.1642,  0.0758,  0.1047, -0.4354,  0.0194, -0.3876,\n",
            "          0.1271, -0.2790,  0.0655, -0.0678,  0.0796, -0.0875, -0.0067, -0.2535,\n",
            "          0.2273,  0.3126, -0.2808,  0.3202],\n",
            "        [ 0.0910, -0.1505,  0.0051, -0.0075,  0.0132,  0.0907,  0.2295, -0.2130,\n",
            "         -0.0722, -0.5722, -0.0830,  0.3650,  0.3065,  0.1141, -0.1431, -0.3333,\n",
            "         -0.0598,  0.3623, -0.4334,  0.0089],\n",
            "        [-0.2783,  0.1234, -0.0809,  0.2937,  0.5018, -0.0033,  0.0937, -0.2188,\n",
            "         -0.4057,  0.2510,  0.2627,  0.3632, -0.1708, -0.2961,  0.2212, -0.2358,\n",
            "         -0.0350, -0.0136,  0.2133,  0.1359],\n",
            "        [ 0.1311, -0.2007,  0.1342,  0.0387,  0.0246,  0.3952, -0.2456,  0.0643,\n",
            "          0.0279, -0.2520,  0.1074, -0.1215, -0.2410,  0.3114, -0.2509,  0.0310,\n",
            "         -0.4009,  0.3474, -0.1086,  0.1508]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **<font style=\"color:darkgreen\">Implementing an LSTM with Attention and Entropic regularization from scratch in *PyTorch*</font>**"
      ],
      "metadata": {
        "id": "HCrUEIVaCcw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMWithAttentionEntropyReg(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, lambda_entropy):\n",
        "        super(LSTMWithAttentionEntropyReg, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lambda_entropy = lambda_entropy\n",
        "\n",
        "        # LSTM weights and biases\n",
        "        self.weights_ih = nn.Parameter(torch.Tensor(4 * hidden_size, input_size))\n",
        "        self.weights_hh = nn.Parameter(torch.Tensor(4 * hidden_size, hidden_size))\n",
        "        self.bias_ih = nn.Parameter(torch.Tensor(4 * hidden_size))\n",
        "        self.bias_hh = nn.Parameter(torch.Tensor(4 * hidden_size))\n",
        "\n",
        "        # Attention weights (kept for compatibility, not used directly)\n",
        "        self.attention_weights = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "\n",
        "        # Fully connected layer for output\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        # Initialize weights\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        nn.init.xavier_uniform_(self.weights_ih)\n",
        "        nn.init.xavier_uniform_(self.weights_hh)\n",
        "        nn.init.zeros_(self.bias_ih)\n",
        "        nn.init.zeros_(self.bias_hh)\n",
        "        nn.init.xavier_uniform_(self.attention_weights)\n",
        "\n",
        "    def lstm_cell_attention_entropy_reg(self, input_tensor, hidden_state, cell_state, previous_hidden_states, timestep):\n",
        "        # Linear transformation (fused)\n",
        "        gates = torch.matmul(input_tensor, self.weights_ih.t()) + self.bias_ih + torch.matmul(hidden_state, self.weights_hh.t()) + self.bias_hh\n",
        "\n",
        "        # Splitting into individual gates\n",
        "        input_gate = torch.sigmoid(gates[:, 0:self.hidden_size])\n",
        "        forget_gate = torch.sigmoid(gates[:, self.hidden_size:2 * self.hidden_size])\n",
        "        output_gate = torch.sigmoid(gates[:, 2 * self.hidden_size:3 * self.hidden_size])\n",
        "        cell_gate = torch.tanh(gates[:, 3 * self.hidden_size:4 * self.hidden_size])\n",
        "\n",
        "        # Updating the cell state\n",
        "        cell_state = forget_gate * cell_state + input_gate * cell_gate\n",
        "\n",
        "        # Attention mechanism\n",
        "        relevant_hidden_states = previous_hidden_states[:, :timestep + 1, :]  # Shape: (batch_size, timestep + 1, hidden_size)\n",
        "        if timestep > 0:  # Only apply attention if there are previous states\n",
        "            # Compute attention scores over the sequence\n",
        "            attention_scores = torch.bmm(relevant_hidden_states, hidden_state.unsqueeze(2)).squeeze(2)  # Shape: (batch_size, timestep + 1)\n",
        "            attention_weights_normalized = F.softmax(attention_scores, dim=1)  # Shape: (batch_size, timestep + 1)\n",
        "            context_vector = torch.bmm(attention_weights_normalized.unsqueeze(1), relevant_hidden_states).squeeze(1)  # Shape: (batch_size, hidden_size)\n",
        "\n",
        "            # Calculate entropy of attention weights\n",
        "            entropy = -torch.sum(attention_weights_normalized * torch.log(attention_weights_normalized + 1e-8), dim=1).mean()\n",
        "        else:\n",
        "            context_vector = torch.zeros_like(hidden_state, device=hidden_state.device)  # No attention at t=0\n",
        "            entropy = torch.tensor(0.0, device=hidden_state.device)\n",
        "\n",
        "        # Update hidden state with context vector and entropy regularization\n",
        "        hidden_state = output_gate * torch.tanh(cell_state) + context_vector - self.lambda_entropy * entropy\n",
        "\n",
        "        return hidden_state, cell_state\n",
        "\n",
        "    def forward(self, x, h_prev, c_prev):\n",
        "        batch_size, seq_length, _ = x.size()\n",
        "        hidden_seq = []\n",
        "        previous_hidden_states = torch.zeros(batch_size, seq_length, self.hidden_size, device=x.device)\n",
        "\n",
        "        h_t, c_t = h_prev, c_prev\n",
        "        for t in range(seq_length):\n",
        "            h_t, c_t = self.lstm_cell_attention_entropy_reg(\n",
        "                x[:, t, :], h_t, c_t, previous_hidden_states, t\n",
        "            )\n",
        "            hidden_seq.append(h_t)\n",
        "            previous_hidden_states[:, t, :] = h_t\n",
        "\n",
        "        out = self.fc(hidden_seq[-1])\n",
        "        return out, h_t, c_t\n",
        "\n",
        "# Example usage\n",
        "input_size = 10\n",
        "hidden_size = 20\n",
        "output_size = 1\n",
        "lambda_entropy = 0.1  # Example value for entropic regularization coefficient\n",
        "\n",
        "lstm_attention_entropy = LSTMWithAttentionEntropyReg(input_size, hidden_size, output_size, lambda_entropy)\n",
        "\n",
        "# Dummy input data: (batch_size, seq_length, input_size)\n",
        "batch_size = 5\n",
        "seq_length = 3\n",
        "\n",
        "# Create random input data\n",
        "dummy_input = torch.randn(batch_size, seq_length, input_size)\n",
        "\n",
        "# Initialize hidden and cell states\n",
        "h_prev = torch.zeros(batch_size, hidden_size)\n",
        "c_prev = torch.zeros(batch_size, hidden_size)\n",
        "\n",
        "# Forward pass\n",
        "outputs, h_t, c_t = lstm_attention_entropy(dummy_input, h_prev, c_prev)\n",
        "\n",
        "# Print the outputs\n",
        "print(\"Outputs:\", outputs)\n",
        "print(\"Final Hidden State:\", h_t)\n",
        "print(\"Final Cell State:\", c_t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tdgp44XfCdEH",
        "outputId": "9d1a527f-f01b-4ba6-c4e6-329dc081eb07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs: tensor([[ 0.2114],\n",
            "        [ 0.0290],\n",
            "        [-0.0084],\n",
            "        [-0.0736],\n",
            "        [ 0.0737]], grad_fn=<AddmmBackward0>)\n",
            "Final Hidden State: tensor([[-0.0070, -0.0495, -0.2752,  0.0615, -0.5194, -0.2094, -0.1195,  0.2727,\n",
            "          0.0814,  0.0543, -0.4781, -0.1982, -0.1221, -0.3339, -0.0385, -0.0234,\n",
            "         -0.1176, -0.0592, -0.3543, -0.2200],\n",
            "        [ 0.0406, -0.2710, -0.2743, -0.2181, -0.0642, -0.1334, -0.0652, -0.3198,\n",
            "         -0.1654, -0.1630, -0.0755,  0.0832, -0.0079, -0.1591, -0.2275, -0.3423,\n",
            "          0.0059, -0.1045, -0.0116, -0.0641],\n",
            "        [ 0.0285, -0.2609, -0.2609, -0.0312, -0.2454, -0.1235, -0.3099, -0.1987,\n",
            "         -0.1123, -0.4523,  0.1828, -0.2153, -0.2300,  0.0601, -0.2447, -0.4044,\n",
            "         -0.0421, -0.3750, -0.2686, -0.4113],\n",
            "        [-0.0636, -0.3021,  0.0596, -0.1750, -0.1481, -0.1398, -0.0971, -0.1303,\n",
            "         -0.1330, -0.2915, -0.2627,  0.0214,  0.0948, -0.1947, -0.0324, -0.4557,\n",
            "         -0.3211, -0.2672, -0.1322, -0.3268],\n",
            "        [-0.1269,  0.0709, -0.2965, -0.0974, -0.2359, -0.3074, -0.4102, -0.0842,\n",
            "         -0.0596, -0.1772, -0.2849, -0.2563, -0.0024, -0.1432, -0.0768, -0.3049,\n",
            "         -0.0727, -0.3340, -0.2498, -0.1828]], grad_fn=<SubBackward0>)\n",
            "Final Cell State: tensor([[ 0.2374, -0.0243, -0.1848,  0.1369, -0.5024, -0.0643,  0.2152,  0.4884,\n",
            "          0.2128,  0.2269, -0.3647, -0.0252,  0.0552, -0.2930,  0.0305,  0.2107,\n",
            "          0.0737,  0.2775, -0.0786, -0.0434],\n",
            "        [ 0.1781, -0.2351, -0.1549, -0.0845,  0.0795,  0.0132,  0.2745, -0.3492,\n",
            "         -0.0984,  0.0888,  0.0423,  0.2691,  0.1912, -0.0279, -0.1642, -0.2104,\n",
            "          0.1966,  0.1627,  0.2648,  0.2248],\n",
            "        [ 0.2960,  0.0570, -0.3337,  0.1749, -0.2280, -0.0804, -0.3523, -0.0334,\n",
            "          0.0944, -0.4696,  0.3724, -0.1074, -0.0595,  0.1182, -0.1120, -0.4604,\n",
            "          0.1866, -0.4302, -0.3102, -0.3917],\n",
            "        [ 0.0830, -0.0938,  0.0654, -0.1360,  0.1540, -0.1217,  0.0130, -0.0079,\n",
            "          0.0432, -0.2350, -0.1604,  0.1302,  0.4031, -0.1422,  0.1763, -0.4660,\n",
            "         -0.1513, -0.2303,  0.0138, -0.2632],\n",
            "        [ 0.0491,  0.2971, -0.1690, -0.2620,  0.0772, -0.2296, -0.3861, -0.0939,\n",
            "          0.0292,  0.1265, -0.0246, -0.2956,  0.2539,  0.0463, -0.0322, -0.3257,\n",
            "          0.2783, -0.2661, -0.0600,  0.1636]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<font style=\"color:aqua\">Time factor (time decay)</font>**"
      ],
      "metadata": {
        "id": "H7efB2GOGaRh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **<font style=\"color:brown\">Mathematical expression with time factor:</font>**\n",
        "\n",
        "1. **Equations:**\n",
        "\n",
        "- *Fused linear transformation for gates: (Same as before)*\n",
        "\n",
        "$$\\mathbf{\\text{gates}} = x_t W_{ih}^T + b_{ih} + h_{t-1} W_{hh}^T + b_{hh}$$\n",
        "\n",
        "- *Dividing the gates and applying activation functions: (Same as before)*\n",
        "\n",
        "$$i_t = \\sigma(\\mathbf{gates}_{[0:n]})$$\n",
        "$$f_t = \\sigma(\\mathbf{gates}_{[n:2n]})$$\n",
        "$$o_t = \\sigma(\\mathbf{gates}_{[2n:3n]})$$\n",
        "$$g_t = \\tanh(\\mathbf{gates}_{[3n:4n]})$$\n",
        "\n",
        "- *Cell status update: (Same as before)*\n",
        "\n",
        "$$c_t = f_t \\odot c_{t-1} + i_t \\odot g_t$$\n",
        "\n",
        "- *Attention Score Calculation: (Same as before)*\n",
        "\n",
        "$$\\mathbf{\\text{attention_scores}} = h_{t-1} W_{attn}^T$$\n",
        "\n",
        "- *Applying temporal decay to attention weights:*\n",
        "  - *First, the nonlinear attention weights are calculated:*\n",
        "\n",
        "  $$\n",
        "  \\mathbf{\\text{attention_weights_unnormalized}} = \\exp(\\mathbf{\\text{attention_scores}})\n",
        "  $$\n",
        "\n",
        "  - *Then, time decay is applied:*\n",
        "\n",
        "  $$\n",
        "  \\mathbf{\\text{time_weights}} = \\exp(-\\delta \\cdot [0, 1, \\dots, t])\n",
        "  $$\n",
        "\n",
        "  >where $\\delta$ is the time decay coefficient (time_decay) and $[0,1,\\dots,t]$ is the vector of time indices of previous hidden states (relative to the current step).\n",
        "\n",
        "  - *Combined scales:*\n",
        "\n",
        "$$\n",
        "\\mathbf{\\text{attention_weights_with_decay}} = \\mathbf{\\text{attention_weights_unnormalized}} \\odot \\mathbf{\\text{time_weights}}\n",
        "$$\n",
        "\n",
        "- *Normalization of attention weights with temporal decay:*\n",
        "\n",
        "$$\n",
        "\\mathbf{\\text{attention_weights_normalized}} = \\frac{\\mathbf{\\text{attention_weights_with_decay}}}{\\sum_{i=0}^{t} \\mathbf{\\text{attention_weights_with_decay}}_i}\n",
        "$$\n",
        "\n",
        ">Normalization is performed over the dimension of the sequence of previous hidden states.\n",
        "\n",
        "- *Context vector calculation: (Same as before, but with time-dampened weights)*\n",
        "\n",
        "$$\n",
        "\\mathbf{\\text{context_vector}} = \\mathbf{\\text{attention_weights_normalized}} \\, H_{prev}^{(0:t+1)}\n",
        "$$\n",
        "\n",
        ">where $H_{prev}^{(0:t+1)}$ denotes the sequence of previous hidden states up to the current time step\n",
        "\n",
        "- *Updating the hidden state with the context vector: (Same as before)*\n",
        "\n",
        "$$\n",
        "h_t = o_t \\odot \\tanh(c_t) + \\mathbf{\\text{context_vector}}\n",
        "$$\n",
        "\n",
        "2. **Dependencies:**\n",
        "\n",
        "  In addition to the dependencies from the clean version with attention, the updated hidden state ht now also depends on:\n",
        "\n",
        "  - Time decay coefficient $\\delta$ (`time_decay`).\n",
        "  - The current time step $t$ for calculating time weights.\n"
      ],
      "metadata": {
        "id": "XAB-MhxJJzpg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **<font style=\"color:darkgreen\">Implementing an LSTM with Time factor as function from scratch in *PyTorch*</font>**"
      ],
      "metadata": {
        "id": "WHnOC0v9dext"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **<font style=\"color:green\">Definition LSTM with Time factor as function</font>**"
      ],
      "metadata": {
        "id": "VQycT3sFdug7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm_cell_attention_time_decay(input_tensor, hidden_state, cell_state, weights_ih, weights_hh, bias_ih, bias_hh, attention_weights, previous_hidden_states, timestep, time_decay):\n",
        "    \"\"\"\n",
        "    Calculation of a single step of an LSTM cell with an attention mechanism and time decay.\n",
        "\n",
        "    Args:\n",
        "        input_tensor: Input tensor (x_t)\n",
        "        hidden_state: Hidden state from the previous step (h_{t-1})\n",
        "        cell_state: Cell state from the previous step (c_{t-1})\n",
        "        weights_ih: Weights for the input tensor\n",
        "        weights_hh: Weights for the hidden state\n",
        "        bias_ih: Biases for the input tensor\n",
        "        bias_hh: Biases for the hidden state\n",
        "        attention_weights: Attention weights (not used directly here, kept for compatibility)\n",
        "        previous_hidden_states: Hidden states from previous steps\n",
        "        timestep: Current timestep in the sequence\n",
        "        time_decay: Coefficient of time decay\n",
        "\n",
        "    Returns:\n",
        "        New hidden state (h_t) and new cell state (c_t)\n",
        "    \"\"\"\n",
        "\n",
        "    # Linear transformation (fused)\n",
        "    gates = torch.matmul(input_tensor, weights_ih.t()) + bias_ih + torch.matmul(hidden_state, weights_hh.t()) + bias_hh\n",
        "\n",
        "    # Splitting into individual gates\n",
        "    input_gate = torch.sigmoid(gates[:, 0:hidden_state.shape[1]])\n",
        "    forget_gate = torch.sigmoid(gates[:, hidden_state.shape[1]:2 * hidden_state.shape[1]])\n",
        "    output_gate = torch.sigmoid(gates[:, 2 * hidden_state.shape[1]:3 * hidden_state.shape[1]])\n",
        "    cell_gate = torch.tanh(gates[:, 3 * hidden_state.shape[1]:4 * hidden_state.shape[1]])\n",
        "\n",
        "    # Updating the cell state\n",
        "    cell_state = forget_gate * cell_state + input_gate * cell_gate\n",
        "\n",
        "    # Attention\n",
        "    relevant_hidden_states = previous_hidden_states[:, :timestep + 1, :]\n",
        "    if timestep > 0:\n",
        "        # Compute attention scores\n",
        "        attention_scores = torch.bmm(relevant_hidden_states, hidden_state.unsqueeze(2)).squeeze(2)\n",
        "        attention_weights_unnormalized = torch.exp(attention_scores) # Using exponential for non-negative weights\n",
        "\n",
        "        # Apply time decay to attention weights\n",
        "        time_weights = torch.exp(-time_decay * torch.arange(timestep + 1).float().to(input_tensor.device))\n",
        "        time_weights = time_weights.unsqueeze(0) # Add batch dimension\n",
        "        attention_weights_with_decay = attention_weights_unnormalized * time_weights\n",
        "\n",
        "        # Normalize attention weights with decay\n",
        "        attention_weights_normalized = attention_weights_with_decay / torch.sum(attention_weights_with_decay, dim=1, keepdim=True)\n",
        "\n",
        "        # Compute context vector\n",
        "        context_vector = torch.bmm(attention_weights_normalized.unsqueeze(1), relevant_hidden_states).squeeze(1)\n",
        "    else:\n",
        "        context_vector = torch.zeros_like(hidden_state, device=hidden_state.device)\n",
        "\n",
        "    # Updating the hidden state with the context vector\n",
        "    hidden_state = output_gate * torch.tanh(cell_state) + context_vector\n",
        "\n",
        "    return hidden_state, cell_state"
      ],
      "metadata": {
        "id": "RoT9XjcyGaZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **<font style=\"color:green\">Application lstm_cell_attention_time_decay function</font>**"
      ],
      "metadata": {
        "id": "ZW_3DzXleOIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModelWithAttentionTimeDecay(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, time_decay):\n",
        "        super(LSTMModelWithAttentionTimeDecay, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.time_decay = time_decay\n",
        "        self.weights_ih = nn.Parameter(torch.Tensor(4 * hidden_size, input_size))\n",
        "        self.weights_hh = nn.Parameter(torch.Tensor(4 * hidden_size, hidden_size))\n",
        "        self.bias_ih = nn.Parameter(torch.Tensor(4 * hidden_size))\n",
        "        self.bias_hh = nn.Parameter(torch.Tensor(4 * hidden_size))\n",
        "        self.attention_weights = nn.Parameter(torch.Tensor(hidden_size, hidden_size)) # Kept for compatibility\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        nn.init.xavier_uniform_(self.weights_ih)\n",
        "        nn.init.xavier_uniform_(self.weights_hh)\n",
        "        nn.init.zeros_(self.bias_ih)\n",
        "        nn.init.zeros_(self.bias_hh)\n",
        "        nn.init.xavier_uniform_(self.attention_weights)\n",
        "\n",
        "    def forward(self, x, h_prev, c_prev):\n",
        "        batch_size, seq_length, _ = x.size()\n",
        "        hidden_seq = []\n",
        "        previous_hidden_states = torch.zeros(batch_size, seq_length, self.hidden_size, device=x.device)\n",
        "\n",
        "        h_t, c_t = h_prev, c_prev\n",
        "        for t in range(seq_length):\n",
        "            h_t, c_t = lstm_cell_attention_time_decay(\n",
        "                x[:, t, :], h_t, c_t, self.weights_ih, self.weights_hh,\n",
        "                self.bias_ih, self.bias_hh, self.attention_weights, previous_hidden_states, t, self.time_decay\n",
        "            )\n",
        "            hidden_seq.append(h_t)\n",
        "            previous_hidden_states[:, t, :] = h_t\n",
        "\n",
        "        out = self.fc(hidden_seq[-1])\n",
        "        return out, h_t, c_t\n",
        "\n",
        "# Example usage\n",
        "input_size = 10\n",
        "hidden_size = 20\n",
        "output_size = 1\n",
        "time_decay = 0.1 # Example value for time decay coefficient\n",
        "\n",
        "lstm_cell_attention_decay = LSTMModelWithAttentionTimeDecay(input_size, hidden_size, output_size, time_decay)\n",
        "\n",
        "# Dummy input data\n",
        "batch_size = 5\n",
        "seq_length = 3\n",
        "dummy_input = torch.randn(batch_size, seq_length, input_size)\n",
        "\n",
        "# Initialize hidden and cell states\n",
        "h_prev = torch.zeros(batch_size, hidden_size)\n",
        "c_prev = torch.zeros(batch_size, hidden_size)\n",
        "\n",
        "# Forward pass\n",
        "outputs, h_t, c_t = lstm_cell_attention_decay(dummy_input, h_prev, c_prev)\n",
        "\n",
        "# Print the outputs\n",
        "print(\"Outputs:\", outputs)\n",
        "print(\"Final Hidden State:\", h_t)\n",
        "print(\"Final Cell State:\", c_t)"
      ],
      "metadata": {
        "id": "KngdfzlVeOT7",
        "outputId": "c1859a8f-dd77-4910-c6bc-b25eae317c69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs: tensor([[-0.2462],\n",
            "        [-0.2267],\n",
            "        [-0.1978],\n",
            "        [-0.2007],\n",
            "        [-0.0557]], grad_fn=<AddmmBackward0>)\n",
            "Final Hidden State: tensor([[-0.2260,  0.0501,  0.1519, -0.1547, -0.1071,  0.0655, -0.0388, -0.1138,\n",
            "          0.3055, -0.1080,  0.0231, -0.0923,  0.1430,  0.0915,  0.3307, -0.2310,\n",
            "          0.0665,  0.0929, -0.0202,  0.0228],\n",
            "        [-0.1716, -0.2355, -0.3021,  0.3116,  0.1555, -0.3448, -0.1408, -0.3954,\n",
            "         -0.2097,  0.0034,  0.1344, -0.1456, -0.1281,  0.3666, -0.2645,  0.1204,\n",
            "         -0.1859,  0.1279,  0.0859, -0.2702],\n",
            "        [-0.0016,  0.4163, -0.0074, -0.0998,  0.0203, -0.0492,  0.0128,  0.0075,\n",
            "          0.1132, -0.0957,  0.1964,  0.1796,  0.1021, -0.1004,  0.0075,  0.0749,\n",
            "         -0.0849,  0.0921, -0.0986,  0.2324],\n",
            "        [ 0.0453, -0.1593,  0.1412,  0.1954,  0.1722,  0.0193,  0.1081, -0.0715,\n",
            "          0.0897, -0.0848,  0.0417,  0.0289, -0.2367, -0.0887, -0.2077,  0.0742,\n",
            "          0.1615, -0.0897, -0.2112, -0.2190],\n",
            "        [-0.2025, -0.0176, -0.0805,  0.0474, -0.0955, -0.0570,  0.1104, -0.0364,\n",
            "          0.2210,  0.1070, -0.1998, -0.3005, -0.2309, -0.2491, -0.1809,  0.0330,\n",
            "          0.0730,  0.0153,  0.1642,  0.0070]], grad_fn=<AddBackward0>)\n",
            "Final Cell State: tensor([[-3.7092e-01, -1.1931e-02,  1.5867e-01, -5.9142e-02, -2.3892e-01,\n",
            "          9.1475e-02,  2.3622e-01,  3.1521e-02,  4.9379e-01, -7.3799e-03,\n",
            "          9.2319e-02, -1.6305e-01,  2.9462e-01,  3.5169e-02,  5.2637e-01,\n",
            "         -1.5081e-01,  5.3171e-02,  1.6285e-01,  4.4408e-02,  1.8286e-01],\n",
            "        [-3.9906e-01, -3.1120e-02, -3.6946e-01,  3.2419e-01,  1.5978e-01,\n",
            "         -3.9037e-01, -1.0745e-01, -5.6965e-01, -4.8406e-01, -9.5089e-02,\n",
            "          3.1620e-01, -1.7152e-01, -7.9123e-02,  2.2695e-01, -3.3280e-02,\n",
            "          3.1783e-02, -2.6284e-01,  3.9731e-01,  8.7140e-02, -1.8612e-01],\n",
            "        [ 1.4231e-02,  7.3770e-01, -1.0072e-01, -1.8705e-04,  9.0874e-02,\n",
            "         -7.3047e-02,  6.6100e-02, -4.1262e-02,  1.2530e-01, -1.9458e-01,\n",
            "          1.4951e-01,  2.7867e-01, -5.4002e-02, -1.7019e-01, -1.3789e-01,\n",
            "          2.0895e-01, -2.6247e-01,  7.0072e-02,  2.9178e-02,  4.1542e-01],\n",
            "        [ 3.7496e-01, -2.0647e-01,  3.7953e-01,  6.6674e-02,  1.5100e-01,\n",
            "          5.1786e-02,  2.0994e-01,  6.6667e-02,  1.9314e-01, -4.0006e-01,\n",
            "          4.1558e-02,  2.2866e-01, -3.2705e-01, -1.3750e-01, -3.4843e-01,\n",
            "         -1.0348e-01,  4.7924e-01, -2.8457e-01, -5.2881e-01, -1.4315e-01],\n",
            "        [-2.2052e-01, -2.3180e-02, -9.3556e-02, -1.0579e-01, -1.7986e-01,\n",
            "          5.1075e-02,  3.6651e-02, -1.2880e-01,  9.7673e-02,  1.7047e-01,\n",
            "         -3.9314e-01, -3.6354e-01, -1.8366e-01, -3.1674e-01, -5.3283e-02,\n",
            "         -1.1885e-01,  2.3211e-01, -1.2089e-01,  3.3403e-01, -1.1432e-01]],\n",
            "       grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **<font style=\"color:darkgreen\">Implementing an LSTM with Attention and Time factor from scratch in *PyTorch*</font>**"
      ],
      "metadata": {
        "id": "TzlSLq9AfNP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMWithAttentionTimeDecay(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, time_decay):\n",
        "        super(LSTMWithAttentionTimeDecay, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.time_decay = time_decay\n",
        "\n",
        "        # LSTM weights and biases\n",
        "        self.weights_ih = nn.Parameter(torch.Tensor(4 * hidden_size, input_size))\n",
        "        self.weights_hh = nn.Parameter(torch.Tensor(4 * hidden_size, hidden_size))\n",
        "        self.bias_ih = nn.Parameter(torch.Tensor(4 * hidden_size))\n",
        "        self.bias_hh = nn.Parameter(torch.Tensor(4 * hidden_size))\n",
        "\n",
        "        # Attention weights (kept for compatibility, not used directly)\n",
        "        self.attention_weights = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "\n",
        "        # Fully connected layer for output\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        # Initialize weights\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        nn.init.xavier_uniform_(self.weights_ih)\n",
        "        nn.init.xavier_uniform_(self.weights_hh)\n",
        "        nn.init.zeros_(self.bias_ih)\n",
        "        nn.init.zeros_(self.bias_hh)\n",
        "        nn.init.xavier_uniform_(self.attention_weights)\n",
        "\n",
        "    def lstm_cell_attention_time_decay(self, input_tensor, hidden_state, cell_state, previous_hidden_states, timestep):\n",
        "        # Linear transformation (fused)\n",
        "        gates = torch.matmul(input_tensor, self.weights_ih.t()) + self.bias_ih + torch.matmul(hidden_state, self.weights_hh.t()) + self.bias_hh\n",
        "\n",
        "        # Splitting into individual gates\n",
        "        input_gate = torch.sigmoid(gates[:, 0:self.hidden_size])\n",
        "        forget_gate = torch.sigmoid(gates[:, self.hidden_size:2 * self.hidden_size])\n",
        "        output_gate = torch.sigmoid(gates[:, 2 * self.hidden_size:3 * self.hidden_size])\n",
        "        cell_gate = torch.tanh(gates[:, 3 * self.hidden_size:4 * self.hidden_size])\n",
        "\n",
        "        # Updating the cell state\n",
        "        cell_state = forget_gate * cell_state + input_gate * cell_gate\n",
        "\n",
        "        # Attention mechanism\n",
        "        relevant_hidden_states = previous_hidden_states[:, :timestep + 1, :]  # Shape: (batch_size, timestep + 1, hidden_size)\n",
        "        if timestep > 0:  # Only apply attention if there are previous states\n",
        "            # Compute attention scores\n",
        "            attention_scores = torch.bmm(relevant_hidden_states, hidden_state.unsqueeze(2)).squeeze(2)  # Shape: (batch_size, timestep + 1)\n",
        "            attention_weights_unnormalized = torch.exp(attention_scores)  # Using exponential for non-negative weights\n",
        "\n",
        "            # Apply time decay to attention weights\n",
        "            time_weights = torch.exp(-self.time_decay * torch.arange(timestep + 1).float().to(input_tensor.device))\n",
        "            time_weights = time_weights.unsqueeze(0)  # Add batch dimension\n",
        "            attention_weights_with_decay = attention_weights_unnormalized * time_weights\n",
        "\n",
        "            # Normalize attention weights with decay\n",
        "            attention_weights_normalized = attention_weights_with_decay / torch.sum(attention_weights_with_decay, dim=1, keepdim=True)\n",
        "\n",
        "            # Compute context vector\n",
        "            context_vector = torch.bmm(attention_weights_normalized.unsqueeze(1), relevant_hidden_states).squeeze(1)  # Shape: (batch_size, hidden_size)\n",
        "        else:\n",
        "            context_vector = torch.zeros_like(hidden_state, device=hidden_state.device)  # No attention at t=0\n",
        "\n",
        "        # Update hidden state with context vector\n",
        "        hidden_state = output_gate * torch.tanh(cell_state) + context_vector\n",
        "\n",
        "        return hidden_state, cell_state\n",
        "\n",
        "    def forward(self, x, h_prev, c_prev):\n",
        "        batch_size, seq_length, _ = x.size()\n",
        "        hidden_seq = []\n",
        "        previous_hidden_states = torch.zeros(batch_size, seq_length, self.hidden_size, device=x.device)\n",
        "\n",
        "        h_t, c_t = h_prev, c_prev\n",
        "        for t in range(seq_length):\n",
        "            h_t, c_t = self.lstm_cell_attention_time_decay(\n",
        "                x[:, t, :], h_t, c_t, previous_hidden_states, t\n",
        "            )\n",
        "            hidden_seq.append(h_t)\n",
        "            previous_hidden_states[:, t, :] = h_t\n",
        "\n",
        "        out = self.fc(hidden_seq[-1])\n",
        "        return out, h_t, c_t\n",
        "\n",
        "# Example usage\n",
        "input_size = 10\n",
        "hidden_size = 20\n",
        "output_size = 1\n",
        "time_decay = 0.1  # Example value for time decay coefficient\n",
        "\n",
        "lstm_attention_decay = LSTMWithAttentionTimeDecay(input_size, hidden_size, output_size, time_decay)\n",
        "\n",
        "# Dummy input data: (batch_size, seq_length, input_size)\n",
        "batch_size = 5\n",
        "seq_length = 3\n",
        "\n",
        "# Create random input data\n",
        "dummy_input = torch.randn(batch_size, seq_length, input_size)\n",
        "\n",
        "# Initialize hidden and cell states\n",
        "h_prev = torch.zeros(batch_size, hidden_size)\n",
        "c_prev = torch.zeros(batch_size, hidden_size)\n",
        "\n",
        "# Forward pass\n",
        "outputs, h_t, c_t = lstm_attention_decay(dummy_input, h_prev, c_prev)\n",
        "\n",
        "# Print the outputs\n",
        "print(\"Outputs:\", outputs)\n",
        "print(\"Final Hidden State:\", h_t)\n",
        "print(\"Final Cell State:\", c_t)\n"
      ],
      "metadata": {
        "id": "lBZTLAyLfNmx",
        "outputId": "5b79e869-87e7-4178-b86f-f3114876ba99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs: tensor([[0.1389],\n",
            "        [0.0466],\n",
            "        [0.1392],\n",
            "        [0.0197],\n",
            "        [0.0246]], grad_fn=<AddmmBackward0>)\n",
            "Final Hidden State: tensor([[ 1.4313e-01,  1.6179e-02,  3.0502e-02, -4.5134e-02, -1.3699e-03,\n",
            "         -2.7853e-03,  6.2097e-03,  7.9815e-02, -7.2384e-02, -1.2825e-01,\n",
            "          5.3441e-02,  1.0082e-01,  7.0604e-02,  1.5558e-01,  3.2993e-02,\n",
            "          1.1097e-02,  1.1083e-01,  2.3524e-02,  1.0120e-02, -8.4956e-02],\n",
            "        [ 7.0549e-02, -1.0550e-01,  6.0895e-02,  4.5357e-02, -1.5814e-01,\n",
            "         -5.8171e-02,  6.5578e-02, -2.3328e-02,  3.4137e-05,  5.3071e-02,\n",
            "         -2.9496e-03, -2.3341e-01, -1.5708e-01, -7.1465e-02,  1.2531e-02,\n",
            "         -5.5645e-02, -8.5341e-02, -1.4951e-01, -2.6062e-02, -6.0741e-02],\n",
            "        [ 1.5467e-01, -1.3091e-01,  2.9337e-01,  9.1580e-02,  2.8709e-01,\n",
            "         -7.0603e-02, -1.1427e-02, -1.3236e-01,  4.0336e-02, -8.8092e-03,\n",
            "         -1.1652e-01,  7.6264e-02,  1.3618e-01, -7.8744e-02, -3.2453e-01,\n",
            "          2.1617e-01,  2.1717e-01,  2.3135e-02,  1.7376e-01, -1.9181e-01],\n",
            "        [-9.5963e-03, -1.6383e-01, -7.9029e-02,  1.7545e-01,  6.7503e-02,\n",
            "         -1.6927e-01,  8.4233e-02, -9.8605e-02, -2.1339e-02,  5.3208e-02,\n",
            "         -3.3854e-02, -1.8931e-01, -1.5174e-01, -2.9305e-01, -1.8341e-01,\n",
            "          6.3295e-02, -7.0893e-02, -2.5063e-02,  1.8949e-01,  5.4001e-03],\n",
            "        [ 1.4196e-01,  9.7863e-02,  1.0336e-01, -2.4879e-02, -1.4386e-01,\n",
            "          8.5307e-02, -4.8638e-02,  2.5639e-01, -4.1227e-03,  4.6695e-02,\n",
            "         -1.2429e-01,  2.0548e-01, -1.2255e-01, -4.2331e-02,  4.4165e-02,\n",
            "         -2.3704e-02,  3.1712e-02,  2.0346e-02, -9.4458e-02, -1.8425e-01]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Final Cell State: tensor([[ 0.2072,  0.0479,  0.0485,  0.0053, -0.0378,  0.1150,  0.0769,  0.2083,\n",
            "         -0.1262, -0.1315, -0.0085,  0.1546, -0.0193,  0.2341,  0.0699, -0.0714,\n",
            "          0.0637,  0.1528,  0.1308, -0.1478],\n",
            "        [ 0.1178, -0.1188, -0.0160, -0.0402, -0.2317, -0.1177,  0.0796,  0.1126,\n",
            "          0.0411,  0.0267, -0.0970, -0.2410, -0.2441, -0.1322,  0.0408, -0.2256,\n",
            "         -0.1031, -0.2374, -0.0314,  0.0098],\n",
            "        [ 0.0641, -0.3674, -0.0753, -0.1968,  0.3185, -0.3325,  0.2429, -0.2435,\n",
            "          0.1028, -0.1434, -0.0269, -0.0093,  0.2239, -0.0522, -0.1738,  0.0106,\n",
            "          0.1012, -0.0417,  0.1210,  0.0205],\n",
            "        [-0.0588, -0.2490, -0.1113,  0.2589,  0.0529, -0.2695,  0.2532, -0.2236,\n",
            "         -0.0186,  0.1537, -0.0013, -0.5058, -0.3515, -0.4500, -0.1932,  0.1553,\n",
            "         -0.2187, -0.0384,  0.2362,  0.0190],\n",
            "        [ 0.3446,  0.0985,  0.0967, -0.1791, -0.3239,  0.1979,  0.0507,  0.4172,\n",
            "          0.0057, -0.0710, -0.1361,  0.1714, -0.2650,  0.0136,  0.0319, -0.0915,\n",
            "         -0.0577,  0.1515, -0.1345, -0.3418]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<font style=\"color:aqua\">Entropic regularization + Time factor + randomness</font>**"
      ],
      "metadata": {
        "id": "kAcliEjT8ImS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **<font style=\"color:brown\">Mathematical expression with a combination of entropy, time factor and randomness:</font>**\n",
        "\n",
        "\n",
        "1. **Equations:**\n",
        "\n",
        "- *Fused linear transformation for gates: (Same as before)*\n",
        "\n",
        "$$\\mathbf{\\text{gates}} = x_t W_{ih}^T + b_{ih} + h_{t-1} W_{hh}^T + b_{hh}$$\n",
        "\n",
        "- *Dividing the gates and applying activation functions: (Same as before)*\n",
        "\n",
        "$$i_t = \\sigma(\\mathbf{\\text{gates}}_{[0:n]})$$\n",
        "$$f_t = \\sigma(\\mathbf{\\text{gates}}_{[n:2n]})$$\n",
        "$$o_t = \\sigma(\\mathbf{\\text{gates}}_{[2n:3n]})$$\n",
        "$$g_t = \\tanh(\\mathbf{\\text{gates}}_{[3n:4n]})$$\n",
        "\n",
        "- *Cell status update: (Same as before)*\n",
        "\n",
        "$$c_t = f_t \\odot c_{t-1} + i_t \\odot g_t$$\n",
        "\n",
        "- *Attention Score Calculation: (Same as before)*\n",
        "\n",
        "$$\\mathbf{\\text{attention_scores}} = h_{t-1} W_{attn}^T$$\n",
        "\n",
        "- *Time-delay application: (Same as in the time-delay version)*\n",
        "<br /><br />\n",
        "$$\n",
        "\\mathbf{\\text{attention_weights_unnormalized}} = \\exp(\\mathbf{\\text{attention_scores}})\n",
        "$$\n",
        "<br />\n",
        "$$\n",
        "\\mathbf{\\text{time_weights}} = \\exp(-\\delta \\cdot [0, 1, \\dots, t])\n",
        "$$\n",
        "<br />\n",
        "$$\n",
        "\\mathbf{\\text{attention_weights_with_decay}} = \\mathbf{\\text{attention_weights_unnormalized}} \\odot \\mathbf{\\text{time_weights}}\n",
        "$$\n",
        "<br />\n",
        "$$\n",
        "\\mathbf{\\text{attention_weights_normalized_base}} = \\frac{\\mathbf{\\text{attention_weights_with_decay}}}{\\sum_{i=0}^{t} \\mathbf{\\text{attention_weights_with_decay}}_i}\n",
        "$$\n",
        "<br />\n",
        "- *Application of randomness:*\n",
        "  With probability $p$ (`random_prob`):\n",
        "<br /><br />\n",
        "$$\n",
        "\\mathbf{\\text{random_mask}} \\sim \\text{Bernoulli}(0.5)\n",
        "$$\n",
        "<br />\n",
        "$$\n",
        "\\mathbf{\\text{attention_weights_normalized}} = \\mathbf{\\text{attention_weights_normalized_base}} \\odot (1 - \\mathbf{\\text{random_mask}})\n",
        "$$\n",
        "<br />\n",
        "$$\n",
        "\\mathbf{\\text{attention_weights_normalized}} = \\frac{\\mathbf{\\text{attention_weights_normalized}}}{\\sum_{i=0}^{t} \\mathbf{\\text{attention_weights_normalized}}_i + \\epsilon}\n",
        "$$\n",
        "\n",
        "Otherwise (with probability $1p$):\n",
        "\n",
        "$$\n",
        "\\mathbf{\\text{attention_weights_normalized}} = \\mathbf{\\text{attention_weights_normalized_base}}\n",
        "$$\n",
        "\n",
        "where $\\epsilon$ is a small number for numerical stability.\n",
        "<br /><br />\n",
        "- *Context vector calculation: (Same as before, with potentially randomly adjusted weights)*\n",
        "<br /><br />\n",
        "$$\\mathbf{\\text{context_vector}} = \\mathbf{\\text{attention_weights_normalized}}  \\, H_{prev}^{(0:t+1)}$$\n",
        "<br />\n",
        "- *Calculation of the entropy of attention weights: (Same as in the version with entropic regularization, on potentially randomly adjusted weights)*\n",
        "<br />\n",
        "$$\n",
        "H(\\mathbf{a}) = - \\frac{1}{B} \\sum_{b=1}^{B} \\sum_{i=0}^{t} a_{b,i} \\log(a_{b,i} + \\epsilon)\n",
        "$$\n",
        "\n",
        "where $\\mathbf{\\text{a}}=\\mathbf{\\text{attention_weights_normalized}}$.\n",
        "<br /><br />\n",
        "- *Hidden state update with context vector and entropic regularization: (Same as in the version with entropic regularization)*\n",
        "\n",
        "$$\n",
        "h_t = o_t \\odot \\tanh(c_t) + \\mathbf{\\text{context_vector}} - \\lambda_{entropy} \\cdot H(\\mathbf{a}) \\cdot \\mathbf{1}\n",
        "$$\n",
        "<br />\n",
        "\n",
        "2. **Dependencies:**\n",
        "\n",
        "In addition to the dependencies from previous versions, the updated hidden state $h_t$ now also depends on:\n",
        "\n",
        "- The probability of random resetting of the attention weights $p$ `(random_prob)`."
      ],
      "metadata": {
        "id": "cn3mNRO0BSdJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **<font style=\"color:darkgreen\">Implementing an LSTM with Entropic regularization + Time factor + randomness as function from scratch in *PyTorch*</font>**"
      ],
      "metadata": {
        "id": "PRWMLkvMBdJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **<font style=\"color:green\">Definition LSTM with Entropic regularization + Time factor + randomness as function</font>**"
      ],
      "metadata": {
        "id": "OdAxCH1oD9vG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm_cell_attention_mixed(input_tensor, hidden_state, cell_state, weights_ih, weights_hh, bias_ih, bias_hh, attention_weights, previous_hidden_states, timestep, lambda_entropy, time_decay, random_prob):\n",
        "    \"\"\"\n",
        "    Calculation of a single step of an LSTM cell with an attention mechanism, entropic regularization,\n",
        "    time decay, and a random element.\n",
        "\n",
        "    Args:\n",
        "        input_tensor: Input tensor (x_t)\n",
        "        hidden_state: Hidden state from the previous step (h_{t-1})\n",
        "        cell_state: Cell state from the previous step (c_{t-1})\n",
        "        weights_ih: Weights for the input tensor\n",
        "        weights_hh: Weights for the hidden state\n",
        "        bias_ih: Biases for the input tensor\n",
        "        bias_hh: Biases for the hidden state\n",
        "        attention_weights: Attention weights (not used directly here, kept for compatibility)\n",
        "        previous_hidden_states: Hidden states from previous steps\n",
        "        timestep: Current timestep in the sequence\n",
        "        lambda_entropy: Coefficient of entropic regularization\n",
        "        time_decay: Coefficient of time decay\n",
        "        random_prob: Probability of applying random zeroing of attention weights\n",
        "\n",
        "    Returns:\n",
        "        New hidden state (h_t) and new cell state (c_t)\n",
        "    \"\"\"\n",
        "    # Linear transformation (fused)\n",
        "    gates = torch.matmul(input_tensor, weights_ih.t()) + bias_ih + torch.matmul(hidden_state, weights_hh.t()) + bias_hh\n",
        "\n",
        "    # Splitting into individual gates\n",
        "    input_gate = torch.sigmoid(gates[:, 0:hidden_state.shape[1]])\n",
        "    forget_gate = torch.sigmoid(gates[:, hidden_state.shape[1]:2 * hidden_state.shape[1]])\n",
        "    output_gate = torch.sigmoid(gates[:, 2 * hidden_state.shape[1]:3 * hidden_state.shape[1]])\n",
        "    cell_gate = torch.tanh(gates[:, 3 * hidden_state.shape[1]:4 * hidden_state.shape[1]])\n",
        "\n",
        "    # Updating the cell state\n",
        "    cell_state = forget_gate * cell_state + input_gate * cell_gate\n",
        "\n",
        "    # Attention\n",
        "    relevant_hidden_states = previous_hidden_states[:, :timestep + 1, :]\n",
        "    if timestep > 0:\n",
        "        # Compute attention scores\n",
        "        attention_scores = torch.bmm(relevant_hidden_states, hidden_state.unsqueeze(2)).squeeze(2)\n",
        "        attention_weights_unnormalized = torch.exp(attention_scores)\n",
        "\n",
        "        # Apply time decay\n",
        "        time_weights = torch.exp(-time_decay * torch.arange(timestep + 1).float().to(input_tensor.device))\n",
        "        time_weights = time_weights.unsqueeze(0)\n",
        "        attention_weights_with_decay = attention_weights_unnormalized * time_weights\n",
        "\n",
        "        # Normalize attention weights\n",
        "        attention_weights_normalized_base = attention_weights_with_decay / torch.sum(attention_weights_with_decay, dim=1, keepdim=True)\n",
        "\n",
        "        # Apply randomness\n",
        "        if random.random() < random_prob:\n",
        "            random_mask = torch.rand(attention_weights_normalized_base.shape, device=input_tensor.device) < 0.5\n",
        "            attention_weights_normalized = attention_weights_normalized_base.masked_fill(random_mask, 0)\n",
        "            attention_weights_normalized = attention_weights_normalized / (torch.sum(attention_weights_normalized, dim=1, keepdim=True) + 1e-8) # Re-normalize\n",
        "        else:\n",
        "            attention_weights_normalized = attention_weights_normalized_base\n",
        "\n",
        "        # Compute context vector\n",
        "        context_vector = torch.bmm(attention_weights_normalized.unsqueeze(1), relevant_hidden_states).squeeze(1)\n",
        "\n",
        "        # Calculate entropy of attention weights\n",
        "        entropy = -torch.sum(attention_weights_normalized * torch.log(attention_weights_normalized + 1e-8), dim=1).mean()\n",
        "    else:\n",
        "        context_vector = torch.zeros_like(hidden_state, device=hidden_state.device)\n",
        "        entropy = torch.tensor(0.0, device=hidden_state.device)\n",
        "\n",
        "    # Updating the hidden state with the context vector and entropic regularization\n",
        "    hidden_state = output_gate * torch.tanh(cell_state) + context_vector - lambda_entropy * entropy\n",
        "\n",
        "    return hidden_state, cell_state"
      ],
      "metadata": {
        "id": "TSQnuD7T8I0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **<font style=\"color:green\">Application lstm_cell_attention_mixed function</font>**"
      ],
      "metadata": {
        "id": "uxvYjtH4EXLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModelWithAttentionMixed(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, lambda_entropy, time_decay, random_prob):\n",
        "        super(LSTMModelWithAttentionMixed, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lambda_entropy = lambda_entropy\n",
        "        self.time_decay = time_decay\n",
        "        self.random_prob = random_prob\n",
        "        self.weights_ih = nn.Parameter(torch.Tensor(4 * hidden_size, input_size))\n",
        "        self.weights_hh = nn.Parameter(torch.Tensor(4 * hidden_size, hidden_size))\n",
        "        self.bias_ih = nn.Parameter(torch.Tensor(4 * hidden_size))\n",
        "        self.bias_hh = nn.Parameter(torch.Tensor(4 * hidden_size))\n",
        "        self.attention_weights = nn.Parameter(torch.Tensor(hidden_size, hidden_size)) # Kept for compatibility\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        nn.init.xavier_uniform_(self.weights_ih)\n",
        "        nn.init.xavier_uniform_(self.weights_hh)\n",
        "        nn.init.zeros_(self.bias_ih)\n",
        "        nn.init.zeros_(self.bias_hh)\n",
        "        nn.init.xavier_uniform_(self.attention_weights)\n",
        "\n",
        "    def forward(self, x, h_prev, c_prev):\n",
        "        batch_size, seq_length, _ = x.size()\n",
        "        hidden_seq = []\n",
        "        previous_hidden_states = torch.zeros(batch_size, seq_length, self.hidden_size, device=x.device)\n",
        "\n",
        "        h_t, c_t = h_prev, c_prev\n",
        "        for t in range(seq_length):\n",
        "            h_t, c_t = lstm_cell_attention_mixed(\n",
        "                x[:, t, :], h_t, c_t, self.weights_ih, self.weights_hh,\n",
        "                self.bias_ih, self.bias_hh, self.attention_weights, previous_hidden_states, t,\n",
        "                self.lambda_entropy, self.time_decay, self.random_prob\n",
        "            )\n",
        "            hidden_seq.append(h_t)\n",
        "            previous_hidden_states[:, t, :] = h_t\n",
        "\n",
        "        out = self.fc(hidden_seq[-1])\n",
        "        return out, h_t, c_t\n",
        "\n",
        "# Example usage\n",
        "input_size = 10\n",
        "hidden_size = 20\n",
        "output_size = 1\n",
        "lambda_entropy = 0.01\n",
        "time_decay = 0.05\n",
        "random_prob = 0.1\n",
        "\n",
        "lstm_cell_attention_mixed_model = LSTMModelWithAttentionMixed(input_size, hidden_size, output_size, lambda_entropy, time_decay, random_prob)\n",
        "\n",
        "# Dummy input data\n",
        "batch_size = 5\n",
        "seq_length = 3\n",
        "dummy_input = torch.randn(batch_size, seq_length, input_size)\n",
        "\n",
        "# Initialize hidden and cell states\n",
        "h_prev = torch.zeros(batch_size, hidden_size)\n",
        "c_prev = torch.zeros(batch_size, hidden_size)\n",
        "\n",
        "# Forward pass\n",
        "outputs, h_t, c_t = lstm_cell_attention_mixed_model(dummy_input, h_prev, c_prev)\n",
        "\n",
        "# Print the outputs\n",
        "print(\"Outputs:\", outputs)\n",
        "print(\"Final Hidden State:\", h_t)\n",
        "print(\"Final Cell State:\", c_t)"
      ],
      "metadata": {
        "id": "6xusvpiWEYAt",
        "outputId": "3bbb896e-12f1-48de-9cb5-fb0d1a6e55b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs: tensor([[ 0.0235],\n",
            "        [-0.2290],\n",
            "        [-0.1742],\n",
            "        [-0.1607],\n",
            "        [-0.1948]], grad_fn=<AddmmBackward0>)\n",
            "Final Hidden State: tensor([[-0.0727,  0.1802, -0.1378, -0.0048,  0.0172, -0.0109, -0.4203, -0.2745,\n",
            "         -0.0861,  0.0189,  0.1795, -0.2878,  0.0609, -0.0398,  0.1126, -0.0660,\n",
            "          0.1473,  0.2862, -0.0826,  0.0294],\n",
            "        [ 0.1567, -0.1339, -0.1536,  0.1871, -0.0574, -0.0453, -0.1006, -0.0891,\n",
            "         -0.3090, -0.1691,  0.0623,  0.1635,  0.1414, -0.0042,  0.3296,  0.0076,\n",
            "          0.0908, -0.1985,  0.0058,  0.0533],\n",
            "        [ 0.0530, -0.2494,  0.2186, -0.0128,  0.2669, -0.0144, -0.0541,  0.1120,\n",
            "         -0.0577,  0.0529,  0.4838, -0.1322,  0.2231, -0.0758, -0.0278, -0.2860,\n",
            "         -0.4349,  0.0722,  0.1455,  0.1568],\n",
            "        [ 0.1200, -0.0583,  0.0665,  0.0193,  0.0690,  0.0589, -0.2641,  0.1823,\n",
            "         -0.2993, -0.1512, -0.0060,  0.1537, -0.2388,  0.0080,  0.2602,  0.2117,\n",
            "          0.0804, -0.3525, -0.0172,  0.1692],\n",
            "        [ 0.1531,  0.1590, -0.1565, -0.0493, -0.1128, -0.0902,  0.0237, -0.0800,\n",
            "         -0.1391, -0.1776,  0.0737, -0.1289, -0.0771,  0.2041, -0.3113,  0.0422,\n",
            "          0.1078,  0.0410, -0.0562, -0.0244]], grad_fn=<SubBackward0>)\n",
            "Final Cell State: tensor([[-0.2306,  0.2186, -0.4325,  0.1510, -0.1818,  0.0897, -0.1088, -0.2996,\n",
            "         -0.0200, -0.0123, -0.0155, -0.1336,  0.1482,  0.1616, -0.0347, -0.0010,\n",
            "          0.4289,  0.2434, -0.1374, -0.4141],\n",
            "        [ 0.3024, -0.1800,  0.0549,  0.1691, -0.1077, -0.1814, -0.2357, -0.1041,\n",
            "         -0.6836,  0.0476,  0.1442,  0.1865,  0.1760, -0.1097,  0.4888,  0.0402,\n",
            "          0.2049, -0.2829, -0.1564,  0.0529],\n",
            "        [ 0.1278, -0.3528,  0.4030, -0.1600,  0.2243,  0.1628, -0.1013,  0.1030,\n",
            "          0.0470,  0.2721,  0.5450,  0.0427,  0.4148, -0.1757,  0.2157, -0.4401,\n",
            "         -0.4342,  0.1694, -0.1024,  0.0554],\n",
            "        [ 0.3495, -0.0656,  0.2943, -0.0329,  0.3026,  0.2377, -0.5962,  0.3573,\n",
            "         -0.3194, -0.1691, -0.0843,  0.2555, -0.2794, -0.0844,  0.4940,  0.1962,\n",
            "          0.0459, -0.4395,  0.0461,  0.2567],\n",
            "        [ 0.1623,  0.1746, -0.2294, -0.0958, -0.3730, -0.1729,  0.2262, -0.1694,\n",
            "         -0.1251,  0.0018,  0.1627, -0.2701,  0.2228,  0.2774, -0.5353,  0.0953,\n",
            "          0.4413,  0.2455, -0.3054, -0.1695]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **<font style=\"color:darkgreen\">Implementing an LSTM with Attention and Entropic regularization + Time factor + randomness from scratch in *PyTorch*</font>**"
      ],
      "metadata": {
        "id": "rioY-EtbJUgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMWithAttentionMixed(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, lambda_entropy, time_decay, random_prob):\n",
        "        super(LSTMWithAttentionMixed, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lambda_entropy = lambda_entropy\n",
        "        self.time_decay = time_decay\n",
        "        self.random_prob = random_prob\n",
        "\n",
        "        # LSTM weights and biases\n",
        "        self.weights_ih = nn.Parameter(torch.Tensor(4 * hidden_size, input_size))\n",
        "        self.weights_hh = nn.Parameter(torch.Tensor(4 * hidden_size, hidden_size))\n",
        "        self.bias_ih = nn.Parameter(torch.Tensor(4 * hidden_size))\n",
        "        self.bias_hh = nn.Parameter(torch.Tensor(4 * hidden_size))\n",
        "\n",
        "        # Attention weights (kept for compatibility, not used directly)\n",
        "        self.attention_weights = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "\n",
        "        # Fully connected layer for output\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        # Initialize weights\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        nn.init.xavier_uniform_(self.weights_ih)\n",
        "        nn.init.xavier_uniform_(self.weights_hh)\n",
        "        nn.init.zeros_(self.bias_ih)\n",
        "        nn.init.zeros_(self.bias_hh)\n",
        "        nn.init.xavier_uniform_(self.attention_weights)\n",
        "\n",
        "    def lstm_cell_attention_mixed(self, input_tensor, hidden_state, cell_state, previous_hidden_states, timestep):\n",
        "        # Linear transformation (fused)\n",
        "        gates = torch.matmul(input_tensor, self.weights_ih.t()) + self.bias_ih + torch.matmul(hidden_state, self.weights_hh.t()) + self.bias_hh\n",
        "\n",
        "        # Splitting into individual gates\n",
        "        input_gate = torch.sigmoid(gates[:, 0:self.hidden_size])\n",
        "        forget_gate = torch.sigmoid(gates[:, self.hidden_size:2 * self.hidden_size])\n",
        "        output_gate = torch.sigmoid(gates[:, 2 * self.hidden_size:3 * self.hidden_size])\n",
        "        cell_gate = torch.tanh(gates[:, 3 * self.hidden_size:4 * self.hidden_size])\n",
        "\n",
        "        # Updating the cell state\n",
        "        cell_state = forget_gate * cell_state + input_gate * cell_gate\n",
        "\n",
        "        # Attention mechanism\n",
        "        relevant_hidden_states = previous_hidden_states[:, :timestep + 1, :]  # Shape: (batch_size, timestep + 1, hidden_size)\n",
        "        if timestep > 0:  # Only apply attention if there are previous states\n",
        "            # Compute attention scores\n",
        "            attention_scores = torch.bmm(relevant_hidden_states, hidden_state.unsqueeze(2)).squeeze(2)  # Shape: (batch_size, timestep + 1)\n",
        "            attention_weights_unnormalized = torch.exp(attention_scores)  # Using exponential for non-negative weights\n",
        "\n",
        "            # Apply time decay to attention weights\n",
        "            time_weights = torch.exp(-self.time_decay * torch.arange(timestep + 1).float().to(input_tensor.device))\n",
        "            time_weights = time_weights.unsqueeze(0)  # Add batch dimension\n",
        "            attention_weights_with_decay = attention_weights_unnormalized * time_weights\n",
        "\n",
        "            # Normalize attention weights with decay\n",
        "            attention_weights_normalized_base = attention_weights_with_decay / torch.sum(attention_weights_with_decay, dim=1, keepdim=True)\n",
        "\n",
        "            # Apply randomness\n",
        "            if random.random() < self.random_prob:\n",
        "                random_mask = torch.rand(attention_weights_normalized_base.shape, device=input_tensor.device) < 0.5\n",
        "                attention_weights_normalized = attention_weights_normalized_base.masked_fill(random_mask, 0)\n",
        "                attention_weights_normalized = attention_weights_normalized / (torch.sum(attention_weights_normalized, dim=1, keepdim=True) + 1e-8)  # Re-normalize\n",
        "            else:\n",
        "                attention_weights_normalized = attention_weights_normalized_base\n",
        "\n",
        "            # Compute context vector\n",
        "            context_vector = torch.bmm(attention_weights_normalized.unsqueeze(1), relevant_hidden_states).squeeze(1)  # Shape: (batch_size, hidden_size)\n",
        "\n",
        "            # Calculate entropy of attention weights\n",
        "            entropy = -torch.sum(attention_weights_normalized * torch.log(attention_weights_normalized + 1e-8), dim=1).mean()\n",
        "        else:\n",
        "            context_vector = torch.zeros_like(hidden_state, device=hidden_state.device)  # No attention at t=0\n",
        "            entropy = torch.tensor(0.0, device=hidden_state.device)\n",
        "\n",
        "        # Update hidden state with context vector and entropy regularization\n",
        "        hidden_state = output_gate * torch.tanh(cell_state) + context_vector - self.lambda_entropy * entropy\n",
        "\n",
        "        return hidden_state, cell_state\n",
        "\n",
        "    def forward(self, x, h_prev, c_prev):\n",
        "        batch_size, seq_length, _ = x.size()\n",
        "        hidden_seq = []\n",
        "        previous_hidden_states = torch.zeros(batch_size, seq_length, self.hidden_size, device=x.device)\n",
        "\n",
        "        h_t, c_t = h_prev, c_prev\n",
        "        for t in range(seq_length):\n",
        "            h_t, c_t = self.lstm_cell_attention_mixed(\n",
        "                x[:, t, :], h_t, c_t, previous_hidden_states, t\n",
        "            )\n",
        "            hidden_seq.append(h_t)\n",
        "            previous_hidden_states[:, t, :] = h_t\n",
        "\n",
        "        out = self.fc(hidden_seq[-1])\n",
        "        return out, h_t, c_t\n",
        "\n",
        "# Example usage\n",
        "input_size = 10\n",
        "hidden_size = 20\n",
        "output_size = 1\n",
        "lambda_entropy = 0.01\n",
        "time_decay = 0.05\n",
        "random_prob = 0.1\n",
        "\n",
        "lstm_attention_mixed_model = LSTMWithAttentionMixed(input_size, hidden_size, output_size, lambda_entropy, time_decay, random_prob)\n",
        "\n",
        "# Dummy input data: (batch_size, seq_length, input_size)\n",
        "batch_size = 5\n",
        "seq_length = 3\n",
        "\n",
        "# Create random input data\n",
        "dummy_input = torch.randn(batch_size, seq_length, input_size)\n",
        "\n",
        "# Initialize hidden and cell states\n",
        "h_prev = torch.zeros(batch_size, hidden_size)\n",
        "c_prev = torch.zeros(batch_size, hidden_size)\n",
        "\n",
        "# Forward pass\n",
        "outputs, h_t, c_t = lstm_attention_mixed_model(dummy_input, h_prev, c_prev)\n",
        "\n",
        "# Print the outputs\n",
        "print(\"Outputs:\", outputs)\n",
        "print(\"Final Hidden State:\", h_t)\n",
        "print(\"Final Cell State:\", c_t)"
      ],
      "metadata": {
        "id": "nbkldBZWJUs1",
        "outputId": "1ac492cc-50e4-4281-8fe4-e0a36a3272b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs: tensor([[-0.0674],\n",
            "        [ 0.0207],\n",
            "        [-0.0804],\n",
            "        [-0.0800],\n",
            "        [-0.0466]], grad_fn=<AddmmBackward0>)\n",
            "Final Hidden State: tensor([[-0.2610,  0.1180,  0.2353, -0.1867, -0.3652,  0.1307, -0.1343, -0.0371,\n",
            "         -0.0416,  0.0566,  0.1276, -0.1949, -0.2405, -0.1488,  0.1876, -0.0643,\n",
            "         -0.0988,  0.2616, -0.4042, -0.1387],\n",
            "        [ 0.0543,  0.0393,  0.2742,  0.2156, -0.5196,  0.0522, -0.2297, -0.5354,\n",
            "         -0.0424,  0.1230,  0.0157, -0.2937,  0.0514, -0.1557, -0.4788,  0.0757,\n",
            "          0.2866, -0.0858,  0.3605,  0.1350],\n",
            "        [ 0.0686, -0.1336,  0.1210, -0.0383, -0.0178,  0.0677, -0.1336, -0.0129,\n",
            "         -0.0361,  0.0057,  0.0869, -0.1719,  0.1145, -0.1220,  0.0319, -0.2331,\n",
            "         -0.1312,  0.2526, -0.1752, -0.0297],\n",
            "        [-0.2814,  0.1112, -0.2019,  0.1308, -0.3655,  0.0941,  0.0491, -0.0887,\n",
            "          0.1313, -0.0188,  0.1232, -0.1748,  0.0527,  0.0626,  0.0978, -0.0658,\n",
            "          0.1218,  0.0743, -0.3277,  0.0340],\n",
            "        [-0.2320, -0.0850, -0.2410,  0.3264, -0.1962, -0.1602,  0.0640,  0.1067,\n",
            "          0.2481, -0.0223,  0.0338,  0.0265,  0.1074,  0.1244,  0.1378,  0.0706,\n",
            "         -0.0035, -0.0356, -0.0389,  0.0178]], grad_fn=<SubBackward0>)\n",
            "Final Cell State: tensor([[-0.4845,  0.2062,  0.2921, -0.1912, -0.8016,  0.1434, -0.1850,  0.0413,\n",
            "          0.0255,  0.1316,  0.2591, -0.2005, -0.2982, -0.2110,  0.4111, -0.0980,\n",
            "         -0.1880,  0.4427, -0.4391, -0.1953],\n",
            "        [ 0.1176,  0.0767,  0.1917,  0.3385, -0.4437,  0.0929, -0.1061, -0.4727,\n",
            "          0.0275,  0.2888,  0.1145, -0.3481,  0.1472, -0.3765, -0.5312, -0.0236,\n",
            "          0.2990, -0.3651,  0.4779,  0.3328],\n",
            "        [ 0.1025, -0.1128,  0.2476, -0.0900, -0.0020,  0.0780, -0.1768,  0.0380,\n",
            "         -0.0557,  0.1193,  0.2035, -0.2340,  0.0948, -0.1718,  0.1318, -0.3587,\n",
            "         -0.2629,  0.4017, -0.2649, -0.0611],\n",
            "        [-0.4080,  0.1133, -0.2800, -0.1268, -0.2813,  0.0722,  0.0131,  0.0116,\n",
            "          0.1886,  0.0311,  0.2219,  0.0009, -0.0463,  0.0329,  0.1716,  0.0247,\n",
            "          0.1187,  0.0347, -0.2088,  0.0637],\n",
            "        [-0.3663, -0.0099, -0.2609,  0.4528, -0.2295, -0.1735,  0.1346,  0.2525,\n",
            "          0.2421, -0.1340,  0.1515,  0.2201,  0.1938,  0.0917,  0.3059,  0.0905,\n",
            "          0.0274, -0.1261, -0.0103,  0.2187]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<font style=\"color:blue\">Calculation of attention weights based on the potential difference principle</font>**\n",
        "\n",
        "------------------------------------------------"
      ],
      "metadata": {
        "id": "ewWaFMlkaj-F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **<font style=\"color:#0080ff\">Physical Principle:</font>**"
      ],
      "metadata": {
        "id": "S8lSQzNgg0gN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>We start from the analogy between electric current and fluid flow, with the driving force for this \"flow\" being the potential difference.</p>\n",
        "\n",
        "- Electricity: Electric current $(\\text{I})$ is proportional to the difference in electrical potentials $(\\text{voltage, U})$ and inversely proportional to the electrical resistance $\\text{(R)}$ according to Ohm's law: $I=U/R$.\n",
        "\n",
        "- Fluids: Fluid flow $\\text{(Q)}$ is proportional to the pressure difference $( \\Delta P)$ and inversely proportional to the hydraulic resistance $(R_h): Q \\, \\propto \\, \\Delta P/R_h$.\n",
        "\n"
      ],
      "metadata": {
        "id": "nA97vie7cbCE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **<font style=\"color:#0080ff\">Our Basic Analogy for Attention:</font>**"
      ],
      "metadata": {
        "id": "XtTjWakJjhW1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **\"Information Flow\" (Attention Weight, $\\alpha_i$)**: Analogous to current $\\text{(I)}$ or flow $\\text{(Q)}$. It represents the extent to which a past hidden state $h_i$ is *\"used\"* to influence the current hidden state $h_t$.\n",
        "\n",
        "- **\"Attention Potential Difference\" $(\\Delta Pattn(t,i))$:** Analogous to voltage difference $(\\Delta U)$ or pressure difference $(\\Delta P)$. It represents the \"driving force\" for the flow of information between the current state and the past state. It is defined as the absolute difference between the \"potential\" of the current hidden state $(P(h_{t1}))$ and the \"potential\" of the past hidden state $(P(h_i))$.\n",
        "\n",
        "$$ \\Delta P_{attn}(t, i) = |P(h_{t-1}) - P(h_i)| $$\n",
        "\n",
        "- **\"Attentional Resistance\" $(R(t,i))$:** Analogous to electrical resistance $(R)$ or hydraulic resistance $(R_h)$. It represents the \"gate\" or \"difficulty\" in the flow of information from the past state $h_i$ to the current state $h_t$. It is modeled as a combination of various factors (temporal distance, semantic distance, etc.).\n",
        "\n",
        "  - ***Combination of various factors:***\n",
        "\n",
        "    1. *Time Resistance $(R_{\\text{time}}(t,i))$*:\n",
        "\n",
        "    $$R_{\\text{time}}(t,i)=exp(\\lambda_{\\text{time}}\\cdot(ti))$$\n",
        "    \n",
        "    where $\\lambda_{\\text{time}}$ is a learnable or fixed parameter controlling the rate of resistance growth with time.\n",
        "\n",
        "    Alternatively:\n",
        "\n",
        "    $$R_{time}(t,i)=1+\\lambda_{time}\\cdot(ti)$$\n",
        "    \n",
        "    2. *Semantic Resistance $(R_{\\text{semantic}}(t,i))$*:\n",
        "\n",
        "    Greater semantic dissimilarity should increase resistance. We can use the cosine distance or the Euclidean distance between $h_{t1}$ and $h_i$ (after any transformation).\n",
        "\n",
        "    $$R_{\\text{semantic}}(t,i)=exp(\\lambda_{\\text{semantic}}\\cdot(1cos(h_{t1},h_i)))$$\n",
        "\n",
        "    Alternatively:\n",
        "\n",
        "    $$R_{\\text{semantic}}(t,i)=1 + \\lambda_{\\text{semantic}} \\cdot \\parallel h_{t1}h_i \\parallel^2$$\n",
        "\n",
        "    3. *Information Saturation Resistance $(R_{\\text{saturation}}(i)):$*\n",
        "\n",
        "    If the past state $h_i$ carries information that is already strongly represented in the context vector or in the current hidden state, its \"resistance\" could increase. This would be more difficult to model and could involve redundancy measurements. For starters, we can omit or simplify this factor.\n",
        "\n",
        "    4. *The total resistance could then be a combination of these factors (e.g. sum or weighted sum):*\n",
        "\n",
        "    $$R(t,i)=R_{\\text{time}}(t,i)+R_{\\text{semantic}}(t,i)(+R_{\\text{saturation}}(i))$$"
      ],
      "metadata": {
        "id": "g2FdSmUojrLb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **<font style=\"color:brown\">Mathematical Description of Information Flow (Attention Scales):</font>**\n",
        "\n",
        "According to our analogy, the \"information flow\" (attention weight) between the current hidden state $h_{t1}$ and the past hidden state $h_i$ is directly proportional to the difference in their \"potentials\" and inversely proportional to the \"resistance\" between them:\n",
        "\n",
        "$$\n",
        "Flow(t,i) \\, \\propto \\, \\frac{\\Delta Pattn(t,i)}{R(t,i)}=\\frac{\\mid P(h_{t1})P(h_i)\\mid}{R(t,i)}\n",
        "$$\n",
        "\n",
        "To obtain normalized attention weights $\\alpha_i$, we apply a softmax function to these \"flows\" over all considered past states:\n",
        "\n",
        "$$\n",
        "\\alpha_i = \\frac{exp(Flow(t,i))}{\\sum_{j}exp(Flow(t,j))} = \\frac{exp(\\frac{\\mid P(h_{t1})P(h_i)\\mid}{R(t,i)})}{\\sum_{j}exp(\\frac{\\mid P(h_{t1})P(h_j)\\mid}{R(t,j)})}\n",
        "$$\n",
        "\n",
        "***Summary of Key Elements:***\n",
        "\n",
        "1. **Potentials $(P(h))$:** A function of a hidden state that quantifies its \"information value\" or \"hunger\" for information. The specific form of this function can be various (norm, entropy, learned transformation).\n",
        "2. **Potential Difference $(\\Delta Pattn(t,i))$:** The absolute difference between the potential of the current and past hidden states, representing the driving force of attention.\n",
        "3. **Resistance $(R(t,i))$:** A function that quantifies the \"difficulty\" of the information flow, depending on temporal and semantic distance (and potentially other factors).\n",
        "4. **Attention Weights $(\\alpha_i)$:** A normalized \"information flow\", determining how much each past state influences the current context vector."
      ],
      "metadata": {
        "id": "5eYcRCMSFszY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NabKEsWgakSN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}